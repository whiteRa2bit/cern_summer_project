{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt.pyll import scope as ho_scope\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 3,
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../problem2')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_data"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_data, get_freq_data"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 5,
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data(is_one_signal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "huber_reg = HuberRegressor()\n",
    "\n",
    "ridge_reg = linear_model.Ridge(alpha=.5)\n",
    "\n",
    "lasso_reg = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "dt_reg = tree.DecisionTreeRegressor()\n",
    "\n",
    "svm_reg = svm.SVR()\n",
    "\n",
    "pa_reg = PassiveAggressiveRegressor(max_iter=1000, random_state=0, tol=1e-3)\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n",
    "\n",
    "catboost_reg = CatBoostRegressor(iterations=100,\n",
    "                          learning_rate=1,\n",
    "                          depth=5)"
=======
    "TIME_SCALE_COEF = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_values = [1, 10, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(iter_num=200):\n",
    "    global X_freq\n",
    "    for freq in freq_values:\n",
    "        X_freq = get_freq_data(X, freq=freq)\n",
    "\n",
    "        best = fmin(\n",
    "            fn=f,  # \"Loss\" function to minimize\n",
    "            space=space,  # Hyperparameter space\n",
    "            algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "            max_evals=iter_num  # Perform 100 trials\n",
    "        )\n",
    "\n",
    "        print('-----------------------------------------------------')\n",
    "        print(\"Freq:\", freq)\n",
    "        print(\"X_freq shape:\", X_freq.shape)\n",
    "        print(\"Found minimum after %d trials:\" %(iter_num))\n",
    "        print(best)\n",
    "        print('-----------------------------------------------------')"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber regressor"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 100/100 [1:57:00<00:00, 72.98s/it, best loss: 0.035768914432610516]\n",
      "Found minimum after 100 trials:\n",
      "{'alpha': 0.00237618197729101, 'epsilon': 2.9405528360024493, 'max_iter': 400.0}\n"
=======
      " 22%|██▏       | 11/50 [07:58<30:16, 46.57s/it, best loss: 0.03724211317323722]"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    huber_reg = HuberRegressor(epsilon=space['epsilon'], max_iter=space['max_iter'], alpha=space['alpha'])\n",
<<<<<<< HEAD
    "    scores = cross_validate(huber_reg, X, y, scoring='neg_mean_absolute_error', cv=5)\n",
=======
    "    scores = cross_validate(huber_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
    "    return TIME_SCALE_COEF * -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'epsilon':  hp.loguniform('epsilon', low=np.log(1.1), high=np.log(10)),\n",
    "    'max_iter': ho_scope.int(hp.quniform('max_iter', low=100, high=500, q=10)),\n",
    "    'alpha':  hp.loguniform('alpha', low=np.log(0.0001), high=np.log(0.01)),\n",
    "}\n",
    "\n",
<<<<<<< HEAD
    "best = fmin(\n",
    "    fn=f,  # \"Loss\" function to minimize\n",
    "    space=space,  # Hyperparameter space\n",
    "    algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "    max_evals=100  # Perform 100 trials\n",
    ")\n",
    "\n",
    "print(\"Found minimum after 100 trials:\")\n",
    "print(best)"
=======
    "global X_freq\n",
    "print_results(iter_num=50)"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regressor"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [22:00<00:00, 31.33s/it, best loss: 0.035771812213692376]\n",
      "Found minimum after 100 trials:\n",
      "{'alpha': 0.03233098093693856, 'max_iter': 2900.0, 'solver': 1}\n"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    ridge_reg = linear_model.Ridge(solver=space['solver'], max_iter=space['max_iter'], alpha=space['alpha'])\n",
    "    scores = cross_validate(ridge_reg, X, y, scoring='neg_mean_absolute_error', cv=5)\n",
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(space):\n",
    "    ridge_reg = linear_model.Ridge(solver=space['solver'], max_iter=space['max_iter'], alpha=space['alpha'])\n",
    "    scores = cross_validate(ridge_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
    "    return TIME_SCALE_COEF * -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'solver': hp.choice('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']),\n",
    "    'max_iter': ho_scope.int(hp.quniform('max_iter', low=1000, high=5000, q=100)),\n",
    "    'alpha':  hp.loguniform('alpha', low=np.log(0.0001), high=np.log(1)),\n",
    "}\n",
    "\n",
<<<<<<< HEAD
    "best = fmin(\n",
    "    fn=f,  # \"Loss\" function to minimize\n",
    "    space=space,  # Hyperparameter space\n",
    "    algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "    max_evals=100  # Perform 100 trials\n",
    ")\n",
    "\n",
    "print(\"Found minimum after 100 trials:\")\n",
    "print(best)"
=======
    "global X_freq\n",
    "print_results(iter_num=50)"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regressor"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": null,
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:37:17<00:00, 68.52s/it, best loss: 0.0366979260657643] \n",
      "Found minimum after 100 trials:\n",
      "{'alpha': 0.00010201681633444055, 'max_iter': 4900.0, 'normalize': 1}\n"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    lasso_reg = linear_model.Lasso(max_iter=space['max_iter'], alpha=space['alpha'], normalize=space['normalize'])\n",
    "    scores = cross_validate(lasso_reg, X, y, scoring='neg_mean_absolute_error', cv=5)\n",
=======
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f(space):\n",
    "    lasso_reg = linear_model.Lasso(max_iter=space['max_iter'], alpha=space['alpha'], normalize=space['normalize'])\n",
    "    scores = cross_validate(lasso_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
    "    return TIME_SCALE_COEF * -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'normalize': hp.choice('normalize', [True, False]),\n",
    "    'max_iter': ho_scope.int(hp.quniform('max_iter', low=1000, high=5000, q=100)),\n",
    "    'alpha':  hp.loguniform('alpha', low=np.log(0.0001), high=np.log(1)),\n",
    "}\n",
    "\n",
<<<<<<< HEAD
    "best = fmin(\n",
    "    fn=f,  # \"Loss\" function to minimize\n",
    "    space=space,  # Hyperparameter space\n",
    "    algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "    max_evals=100  # Perform 100 trials\n",
    ")\n",
    "\n",
    "print(\"Found minimum after 100 trials:\")\n",
    "print(best)"
=======
    "global X_freq\n",
    "print_results(iter_num=50)"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:11<00:00,  3.59s/it, best loss: 0.051637420400257455]\n",
      "Found minimum after 100 trials:\n",
      "{'max_features': 0, 'max_iter': 84.0, 'min_samples_leaf': 8.0, 'min_samples_split': 5.0, 'min_weight_fraction_leaf': 0.0023282482113032308}\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   "source": [
    "def f(space):\n",
    "    dt_reg = tree.DecisionTreeRegressor(max_depth=space['max_depth'], min_samples_split=space['min_samples_split'],\n",
    "                                       min_samples_leaf=space['min_samples_leaf'], min_weight_fraction_leaf=\n",
    "                                        space['min_weight_fraction_leaf'], max_features=space['max_features'])\n",
<<<<<<< HEAD
    "    scores = cross_validate(dt_reg, X, y, scoring='neg_mean_absolute_error', cv=5)\n",
=======
    "    scores = cross_validate(dt_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
    "    return TIME_SCALE_COEF * -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'max_depth':  ho_scope.int(hp.quniform('max_iter', low=4, high=100, q=2)),\n",
    "    'min_samples_split': ho_scope.int(hp.quniform('min_samples_split', low=2, high=10, q=1)),\n",
    "    'min_samples_leaf':  ho_scope.int(hp.quniform('min_samples_leaf', low=1, high=10, q=1)),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0, 0.5),\n",
    "    'max_features': hp.choice('max_features', ['auto', 'sqrt', 'log2'])\n",
    "}\n",
    "\n",
<<<<<<< HEAD
    "best = fmin(\n",
    "    fn=f,  # \"Loss\" function to minimize\n",
    "    space=space,  # Hyperparameter space\n",
    "    algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "    max_evals=100  # Perform 100 trials\n",
    ")\n",
    "\n",
    "print(\"Found minimum after 100 trials:\")\n",
    "print(best)"
=======
    "global X_freq\n",
    "print_results(iter_num=50)"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive aggressive"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:17<00:00,  1.28it/s, best loss: 0.04093956919224103]\n",
      "Found minimum after 100 trials:\n",
      "{'C': 0.010169487581211103, 'max_iter': 2900.0, 'tol': 0.000596334411320511, 'verbose': 94.0}\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   "source": [
    "def f(space):\n",
    "    pa_reg = PassiveAggressiveRegressor(max_iter=space['max_iter'], tol=space['max_iter'], \n",
    "                                       C = space['C'])\n",
<<<<<<< HEAD
    "    scores = cross_validate(pa_reg, X, y, scoring='neg_mean_absolute_error', cv=5)\n",
=======
    "    scores = cross_validate(pa_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
    "    return TIME_SCALE_COEF * -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'max_iter': ho_scope.int(hp.quniform('max_iter', low=1000, high=5000, q=100)),\n",
    "    'tol': hp.loguniform('tol', low=np.log(0.000001), high=np.log(0.001)),\n",
    "    'verbose': ho_scope.int(hp.quniform('verbose', low=1, high=100, q=2)),\n",
    "    'C':  hp.loguniform('C', low=np.log(0.0001), high=np.log(10)),\n",
    "}\n",
    "\n",
<<<<<<< HEAD
    "best = fmin(\n",
    "    fn=f,  # \"Loss\" function to minimize\n",
    "    space=space,  # Hyperparameter space\n",
    "    algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "    max_evals=100  # Perform 100 trials\n",
    ")\n",
    "\n",
    "print(\"Found minimum after 100 trials:\")\n",
    "print(best)"
=======
    "global X_freq\n",
    "print_results(iter_num=50)"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [26:55:48<00:00, 1035.54s/it, best loss: 0.03597189650757139]  \n",
      "Found minimum after 100 trials:\n",
      "{'alpha': 0.2300266294672204, 'booster': 0, 'eta': 0.03169381426736115, 'gamma': 0.007809780191937039, 'lambda': 0.0019067125239897555, 'max_depth': 8.0}\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   "source": [
    "def f(space):\n",
    "    xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", booster=space['booster'], eta=space['eta'], \n",
    "                               gamma=space['gamma'], max_depth=space['max_depth'], reg_lambda=space['lambda'],\n",
    "                               alpha=space['alpha'], verbosity=0)\n",
<<<<<<< HEAD
    "    scores = cross_validate(xgb_reg, X, y, scoring='neg_mean_absolute_error', cv=5)\n",
=======
    "    scores = cross_validate(xgb_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
    "    return TIME_SCALE_COEF * -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'booster': hp.choice('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "    'eta': hp.loguniform('eta', low=np.log(0.001), high=np.log(1)),\n",
    "    'gamma': hp.loguniform('gamma', low=np.log(0.001), high=np.log(100)),\n",
    "    'max_depth': ho_scope.int(hp.quniform('max_depth', low=5, high=50, q=2)),\n",
    "    'lambda': hp.loguniform('lambda', low=np.log(0.001), high=np.log(10)),\n",
    "    'alpha':  hp.loguniform('alpha', low=np.log(0.001), high=np.log(10)),\n",
    "}\n",
    "\n",
<<<<<<< HEAD
    "best = fmin(\n",
    "    fn=f,  # \"Loss\" function to minimize\n",
    "    space=space,  # Hyperparameter space\n",
    "    algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "    max_evals=100  # Perform 100 trials\n",
    ")\n",
    "\n",
    "print(\"Found minimum after 100 trials:\")\n",
    "print(best)"
=======
    "global X_freq\n",
    "print_results(iter_num=50)"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.4"
=======
   "version": "3.6.9"
>>>>>>> e4dcd5c0b4b6e0d33a5d5dfd4c0fa7cb64088575
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
