{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('./data/X.npy')\n",
    "X_polynomial = np.load('./data/X_polynomial.npy')\n",
    "y = np.load('./data/y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_reg = HuberRegressor(epsilon= 5.09, alpha= 0.0004)\n",
    "ridge_reg = linear_model.Ridge(solver='saga', max_iter=4000, alpha= 0.582)\n",
    "lasso_reg = linear_model.Lasso(max_iter=4000, alpha=0.0038, normalize=False)\n",
    "dt_reg = tree.DecisionTreeRegressor(min_samples_split=7, min_samples_leaf=7, min_weight_fraction_leaf=0.000516, \n",
    "                                                                                             max_features='auto')\n",
    "    \n",
    "pa_reg = PassiveAggressiveRegressor(max_iter=3600, tol=1e-3)\n",
    "xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", alpha= 0.00244, booster='dart', eta= 0.017326, gamma=0.19504, \n",
    "                           reg_lambda=0.22451, max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [huber_reg, ridge_reg, lasso_reg, dt_reg, pa_reg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find the best ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_reg = HuberRegressor(epsilon= 5.09, alpha= 0.0004)\n",
    "ridge_reg = linear_model.Ridge(solver='saga', max_iter=4000, alpha= 0.582)\n",
    "lasso_reg = linear_model.Lasso(max_iter=4000, alpha=0.0038, normalize=False)\n",
    "dt_reg = tree.DecisionTreeRegressor(min_samples_split=7, min_samples_leaf=7, min_weight_fraction_leaf=0.000516, \n",
    "                                                                                             max_features='auto')\n",
    "    \n",
    "pa_reg = PassiveAggressiveRegressor(max_iter=3600, tol=1e-3)\n",
    "xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", alpha= 0.00244, booster='dart', eta= 0.017326, gamma=0.19504, \n",
    "                           reg_lambda=0.22451, max_depth=8, verbosity=0)\n",
    "\n",
    "models = [huber_reg, ridge_reg, lasso_reg, dt_reg, xgb_reg, pa_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaregressor: HuberRegressor\n",
      "95% confindence interval:\n",
      "r2_score: 0.99952 (+/- 0.00003)\n",
      "MSE: 0.07790 (+/- 0.00563)\n",
      "MAE: 0.21598 (+/- 0.00477)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: Ridge\n",
      "95% confindence interval:\n",
      "r2_score: 0.99951 (+/- 0.00003)\n",
      "MSE: 0.07886 (+/- 0.00540)\n",
      "MAE: 0.21716 (+/- 0.00445)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: Lasso\n",
      "95% confindence interval:\n",
      "r2_score: 0.99931 (+/- 0.00009)\n",
      "MSE: 0.11194 (+/- 0.01140)\n",
      "MAE: 0.25725 (+/- 0.00805)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: DecisionTreeRegressor\n",
      "95% confindence interval:\n",
      "r2_score: 0.99949 (+/- 0.00003)\n",
      "MSE: 0.08358 (+/- 0.00599)\n",
      "MAE: 0.22507 (+/- 0.00606)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: XGBRegressor\n",
      "95% confindence interval:\n",
      "r2_score: 0.99952 (+/- 0.00002)\n",
      "MSE: 0.07739 (+/- 0.00441)\n",
      "MAE: 0.21611 (+/- 0.00500)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: PassiveAggressiveRegressor\n",
      "95% confindence interval:\n",
      "r2_score: 0.98913 (+/- 0.03609)\n",
      "MSE: 1.75440 (+/- 5.79258)\n",
      "MAE: 0.79214 (+/- 1.59487)\n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "model_names = [type(model).__name__ for model in models]\n",
    "r2_scores_mean = []\n",
    "mse_scores_mean = []\n",
    "mae_scores_mean = []\n",
    "r2_scores_std = []\n",
    "mse_scores_std = []\n",
    "mae_scores_std = []\n",
    "\n",
    "\n",
    "for model in models:    \n",
    "    print(\"Metaregressor:\", type(model).__name__)\n",
    "    stregr = StackingRegressor(regressors=models, meta_regressor=model)\n",
    "    scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "    scores = cross_validate(stregr, X, y, scoring=scoring, cv=5)\n",
    "    \n",
    "    r2_scores_mean.append(scores['test_r2'].mean())\n",
    "    mse_scores_mean.append(-scores['test_neg_mean_squared_error'].mean())\n",
    "    mae_scores_mean.append(-scores['test_neg_mean_absolute_error'].mean())\n",
    "    r2_scores_std.append(scores['test_r2'].std() * 2)\n",
    "    mse_scores_std.append(scores['test_neg_mean_squared_error'].std() * 2)\n",
    "    mae_scores_std.append(scores['test_neg_mean_absolute_error'].std() * 2)\n",
    "    \n",
    "    print(\"95% confidence interval:\")\n",
    "    print(\"r2_score: %0.5f (+/- %0.5f)\" % (scores['test_r2'].mean(), scores['test_r2'].std() * 2))\n",
    "    print(\"MSE: %0.5f (+/- %0.5f)\" % (-scores['test_neg_mean_squared_error'].mean(), scores['test_neg_mean_squared_error'].std() * 2))\n",
    "    print(\"MAE: %0.5f (+/- %0.5f)\" % (-scores['test_neg_mean_absolute_error'].mean(), scores['test_neg_mean_absolute_error'].std() * 2))\n",
    "    print()\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see the best r2_score 0.99952 achieves if using huber regressor as metamodel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
