{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_data, get_freq_data, signal_cyclic_shift, generate_multi_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_origin, y_origin = get_data(data_path='./data/na62_11_pulses.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_origin, y_origin, alpha_range, data_size=1000, to_print=False):\n",
    "    pos_size = int(data_size/2)\n",
    "    neg_size = data_size - pos_size\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(data_size):\n",
    "        alpha = random.choice(alpha_range)\n",
    "        \n",
    "        if i < pos_size:\n",
    "            X.append(random.choice(X_one_signal))\n",
    "#             X.append(generate_multi_signal(X_origin, y_origin, tau, alpha)['first_impulse'])\n",
    "\n",
    "            y.append(1)\n",
    "        else:\n",
    "            X.append(generate_multi_signal(X_origin, y_origin, alpha)['multi_impulse'])\n",
    "            y.append(0)\n",
    "   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "   \n",
    "    if to_print:\n",
    "#         print(\"X positive shape:\", X_positive.shape)\n",
    "#         print(\"y positive shape:\", y_positive.shape)\n",
    "#         print(\"X negative shape:\", X_negative.shape)\n",
    "#         print(\"y negative shape:\", y_negative.shape)\n",
    "        print(\"X shape:\", X.shape)\n",
    "        print(\"y shape:\", y.shape)\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5000, 1024)\n",
      "y shape: (5000,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shuffle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2c78da5f8ba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malpha_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# tau_range = np.arange(-25, 25, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-8b29d59ec57e>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(X_origin, y_origin, alpha_range, data_size, to_print)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shuffle' is not defined"
     ]
    }
   ],
   "source": [
    "alpha_range = np.array([np.around(10**i, decimals=4) for i in np.arange(-3, 3.1, 0.1)])\n",
    "# tau_range = np.arange(-25, 25, 1)\n",
    "X, y = prepare_data(X_origin, y_origin, alpha_range, data_size=5000, to_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "i = random.choice(range(len(X)))\n",
    "plt.title(str(y[i]))\n",
    "plt.plot(X[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_values = [1, 5, 10, 15, 25, 50, 60, 75, 85, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(iter_num=200):\n",
    "    global X_freq\n",
    "    for freq in freq_values:\n",
    "        X_freq = get_freq_data(X, freq=freq)\n",
    "\n",
    "        best = fmin(\n",
    "            fn=f,  # \"Loss\" function to minimize\n",
    "            space=space,  # Hyperparameter space\n",
    "            algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "            max_evals=iter_num  # Perform 100 trials\n",
    "        )\n",
    "\n",
    "        print('-----------------------------------------------------')\n",
    "        print(\"Freq:\", freq)\n",
    "        print(\"X_freq shape:\", X_freq.shape)\n",
    "        print(\"Found minimum after %d trials:\" %(iter_num))\n",
    "        print(best)\n",
    "        print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt.pyll import scope as ho_scope\n",
    "from hyperopt import fmin, tpe, hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(space):\n",
    "        model = KNeighborsClassifier(n_neighbors=space['n_neighbors'], weights=space['weights'],\\\n",
    "                                     algorithm=space['algorithm'], leaf_size=space['leaf_size'], p=space['p'])\n",
    "        scores = cross_validate(model, X_freq, y, scoring='accuracy', cv=5)\n",
    "        return -scores['test_score'].mean()\n",
    "\n",
    "space = {\n",
    "        'n_neighbors': ho_scope.int(hp.quniform('n_neighbors', low=2, high=10, q=1)),\n",
    "        'weights':  hp.choice('weights', ['uniform', 'distance']),\n",
    "        'algorithm': hp.choice('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "        'leaf_size': ho_scope.int(hp.quniform('leaf_size', low=4, high=60, q=2)),\n",
    "        'p': hp.choice('p', [1, 2])\n",
    "}\n",
    "    \n",
    "global X_freq\n",
    "print_results(iter_num=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(space):\n",
    "    model = DecisionTreeClassifier(max_depth=space['max_depth'], max_features=space['max_features'],\\\n",
    "                                  criterion=space['criterion'], min_samples_split=space['min_samples_split'],\\\n",
    "                                  min_samples_leaf=space['min_samples_leaf'], min_weight_fraction_leaf = space['min_weight_fraction_leaf'])\n",
    "    scores = cross_validate(model, X_freq, y, scoring='accuracy', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', ['auto', 'sqrt', 'log2']),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "    'min_samples_split': ho_scope.int(hp.quniform('min_samples_split', low=2, high=10, q=1)),\n",
    "    'min_samples_leaf':  ho_scope.int(hp.quniform('min_samples_leaf', low=1, high=10, q=1)),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0, 0.5),\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(space):\n",
    "    model = RandomForestClassifier(max_depth=space['max_depth'], max_features=space['max_features'],\\\n",
    "                                  criterion=space['criterion'], min_samples_split=space['min_samples_split'],\\\n",
    "                                  min_samples_leaf=space['min_samples_leaf'], min_weight_fraction_leaf = space['min_weight_fraction_leaf'],\\\n",
    "                                  verbose=0)\n",
    "    scores = cross_validate(model, X_freq, y, scoring='accuracy', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', ['auto', 'sqrt', 'log2']),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "    'min_samples_split': ho_scope.int(hp.quniform('min_samples_split', low=2, high=10, q=1)),\n",
    "    'min_samples_leaf':  ho_scope.int(hp.quniform('min_samples_leaf', low=1, high=10, q=1)),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0, 0.5),\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:21<00:00,  2.47it/s, best loss: -0.5478000000000001]\n",
      "-----------------------------------------------------\n",
      "Freq: 1\n",
      "X_freq shape: (5000, 1024)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 3.3508990415658856e-08}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:11<00:00, 17.17it/s, best loss: -0.5466]\n",
      "-----------------------------------------------------\n",
      "Freq: 5\n",
      "X_freq shape: (5000, 204)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 9.475946253489403e-08}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:06<00:00, 29.01it/s, best loss: -0.5450000000000002]\n",
      "-----------------------------------------------------\n",
      "Freq: 10\n",
      "X_freq shape: (5000, 102)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 3.048234025106439e-08}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:05<00:00, 35.34it/s, best loss: -0.5422]\n",
      "-----------------------------------------------------\n",
      "Freq: 15\n",
      "X_freq shape: (5000, 68)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 1.4221606858322495e-10}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:04<00:00, 42.03it/s, best loss: -0.5366000000000001]\n",
      "-----------------------------------------------------\n",
      "Freq: 25\n",
      "X_freq shape: (5000, 41)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 9.528457867564446e-10}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:03<00:00, 53.30it/s, best loss: -0.5346]\n",
      "-----------------------------------------------------\n",
      "Freq: 50\n",
      "X_freq shape: (5000, 20)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 7.592661481121947e-10}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:03<00:00, 51.32it/s, best loss: -0.5346]\n",
      "-----------------------------------------------------\n",
      "Freq: 60\n",
      "X_freq shape: (5000, 17)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 1.0463029297058096e-10}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:03<00:00, 56.05it/s, best loss: -0.5254000000000001]\n",
      "-----------------------------------------------------\n",
      "Freq: 75\n",
      "X_freq shape: (5000, 14)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 8.625177018333479e-09}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:03<00:00, 56.91it/s, best loss: -0.54]\n",
      "-----------------------------------------------------\n",
      "Freq: 85\n",
      "X_freq shape: (5000, 12)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 7.500816391515264e-08}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:03<00:00, 59.04it/s, best loss: -0.5296000000000001]\n",
      "-----------------------------------------------------\n",
      "Freq: 100\n",
      "X_freq shape: (5000, 10)\n",
      "Found minimum after 200 trials:\n",
      "{'var_smoothing': 4.972887130936752e-10}\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    model = GaussianNB(var_smoothing=space['var_smoothing'])\n",
    "    scores = cross_validate(model, X_freq, y, scoring='accuracy', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'var_smoothing': hp.loguniform('var_smoothing', low=np.log(1e-10), high=np.log(1e-7))\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [1:11:07<3:06:05, 279.13s/it, best loss: -0.62]           "
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    model = SVC(C=space['C'], kernel=space['kernel'], degree=space['degree'], gamma=space['gamma'],\\\n",
    "               shrinking=space['shrinking'])\n",
    "    scores = cross_validate(model, X_freq, y, scoring='accuracy', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'C': hp.loguniform('C', low=np.log(0.01), high=np.log(1)),\n",
    "    'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'degree':  ho_scope.int(hp.quniform('degree', low=2, high=5, q=1)),\n",
    "    'gamma':  hp.loguniform('gamma', low=np.log(0.001), high=np.log(100)),\n",
    "    'shrinking': hp.choice('shrinking', [True, False])\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results(iter_num=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:30<00:00,  1.33it/s, best loss: -0.5146]\n",
      "-----------------------------------------------------\n",
      "Freq: 1\n",
      "X_freq shape: (5000, 1024)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.042531592126115486, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:39<00:00,  5.11it/s, best loss: -0.5426]           \n",
      "-----------------------------------------------------\n",
      "Freq: 5\n",
      "X_freq shape: (5000, 204)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.07157846241623136, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:41<00:00,  4.80it/s, best loss: -0.5527999999999998]\n",
      "-----------------------------------------------------\n",
      "Freq: 10\n",
      "X_freq shape: (5000, 102)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.1591828678137072, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:19<00:00, 10.13it/s, best loss: -0.5484]           \n",
      "-----------------------------------------------------\n",
      "Freq: 15\n",
      "X_freq shape: (5000, 68)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.19237176526642727, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:14<00:00, 13.35it/s, best loss: -0.56] \n",
      "-----------------------------------------------------\n",
      "Freq: 25\n",
      "X_freq shape: (5000, 41)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.41918727344243434, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:11<00:00, 17.51it/s, best loss: -0.5386]            \n",
      "-----------------------------------------------------\n",
      "Freq: 50\n",
      "X_freq shape: (5000, 20)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.6470036928562254, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:08<00:00, 22.86it/s, best loss: -0.5306]           \n",
      "-----------------------------------------------------\n",
      "Freq: 60\n",
      "X_freq shape: (5000, 17)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.6393557014884167, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:08<00:00, 23.38it/s, best loss: -0.5197999999999999]\n",
      "-----------------------------------------------------\n",
      "Freq: 75\n",
      "X_freq shape: (5000, 14)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.2908404392124603, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:11<00:00, 17.04it/s, best loss: -0.5162]\n",
      "-----------------------------------------------------\n",
      "Freq: 85\n",
      "X_freq shape: (5000, 12)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.2734619740687327, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:13<00:00, 14.78it/s, best loss: -0.5104]           \n",
      "-----------------------------------------------------\n",
      "Freq: 100\n",
      "X_freq shape: (5000, 10)\n",
      "Found minimum after 200 trials:\n",
      "{'C': 0.29986384195122756, 'fit_intercept': 0}\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    model = PassiveAggressiveClassifier(C=space['C'], fit_intercept=space['fit_intercept'])\n",
    "    scores = cross_validate(model, X_freq, y, scoring='accuracy', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'C': hp.loguniform('C', low=np.log(0.01), high=np.log(1)),\n",
    "    'fit_intercept': hp.choice('fit_intercept', [True, False]),\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [23:37<00:00, 283.51s/it, best loss: -0.5252000000000001]\n",
      "-----------------------------------------------------\n",
      "Freq: 1\n",
      "X_freq shape: (5000, 1024)\n",
      "Found minimum after 5 trials:\n",
      "{'activation': 3, 'first_size': 80.0, 'learning_rate': 2, 'learning_rate_init': 1.6528996498760195e-05, 'max_iter': 300.0, 'second_size': 10.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 5/5 [02:45<00:00, 33.16s/it, best loss: -0.5]\n",
      "-----------------------------------------------------\n",
      "Freq: 5\n",
      "X_freq shape: (5000, 204)\n",
      "Found minimum after 5 trials:\n",
      "{'activation': 1, 'first_size': 60.0, 'learning_rate': 0, 'learning_rate_init': 0.04216946992168108, 'max_iter': 375.0, 'second_size': 10.0}\n",
      "-----------------------------------------------------\n",
      "  0%|          | 0/5 [00:00<?, ?it/s, best loss: ?]"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    model = MLPClassifier(hidden_layer_sizes=(space['first_size'], space['second_size']), \n",
    "                          activation=space['activation'], batch_size=16,\n",
    "                         max_iter=space['max_iter'], learning_rate=space['learning_rate'],\\\n",
    "                         learning_rate_init=space['learning_rate_init'])\n",
    "    scores = cross_validate(model, X_freq, y, scoring='accuracy', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'first_size':  ho_scope.int(hp.quniform('first_size', low=50, high=100, q=10)),\n",
    "    'second_size':  ho_scope.int(hp.quniform('second_size', low=10, high=40, q=5)),\n",
    "    'activation': hp.choice('activation', ['identity', 'logistic', 'tanh', 'relu']),\n",
    "    'learning_rate': hp.choice('learning_rate', ['constant', 'invscaling', 'adaptive']),\n",
    "    'learning_rate_init': hp.loguniform('learning_rate_init', low=np.log(0.00001), high=np.log(0.1)),\n",
    "    'max_iter': ho_scope.int(hp.quniform('max_iter', low=300, high=500, q=25))\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results(iter_num=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-impulse_processing] *",
   "language": "python",
   "name": "conda-env-.conda-impulse_processing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
