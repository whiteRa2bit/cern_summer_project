{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('./data/X.npy')\n",
    "X_polynomial = np.load('./data/X_polynomial.npy')\n",
    "y = np.load('./data/y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_reg = HuberRegressor(epsilon= 5.09, alpha= 0.0004)\n",
    "ridge_reg = linear_model.Ridge(solver='saga', max_iter=4000, alpha= 0.582)\n",
    "lasso_reg = linear_model.Lasso(max_iter=4000, alpha=0.0038, normalize=False)\n",
    "dt_reg = tree.DecisionTreeRegressor(min_samples_split=7, min_samples_leaf=7, min_weight_fraction_leaf=0.000516, \n",
    "                                                                                             max_features='auto')\n",
    "    \n",
    "pa_reg = PassiveAggressiveRegressor(max_iter=3600, tol=1e-3)\n",
    "xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", alpha= 0.00244, booster='dart', eta= 0.017326, gamma=0.19504, \n",
    "                           reg_lambda=0.22451, max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [huber_reg, ridge_reg, lasso_reg, dt_reg, pa_reg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find the best ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_reg = HuberRegressor(epsilon= 5.09, alpha= 0.0004)\n",
    "ridge_reg = linear_model.Ridge(solver='saga', max_iter=4000, alpha= 0.582)\n",
    "lasso_reg = linear_model.Lasso(max_iter=4000, alpha=0.0038, normalize=False)\n",
    "dt_reg = tree.DecisionTreeRegressor(min_samples_split=7, min_samples_leaf=7, min_weight_fraction_leaf=0.000516, \n",
    "                                                                                             max_features='auto')\n",
    "    \n",
    "pa_reg = PassiveAggressiveRegressor(max_iter=3600, tol=1e-3)\n",
    "xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", alpha= 0.00244, booster='dart', eta= 0.017326, gamma=0.19504, \n",
    "                           reg_lambda=0.22451, max_depth=8, verbosity=0)\n",
    "\n",
    "models = [huber_reg, ridge_reg, lasso_reg, dt_reg, xgb_reg, pa_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaregressor: HuberRegressor(alpha=0.0004, epsilon=5.09, fit_intercept=True, max_iter=100,\n",
      "               tol=1e-05, warm_start=False)\n",
      "95% confindence interval:\n",
      "r2_score: 0.99952 (+/- 0.00003)\n",
      "MSE: 0.07785 (+/- 0.00560)\n",
      "MAE: 0.21592 (+/- 0.00473)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: Ridge(alpha=0.582, copy_X=True, fit_intercept=True, max_iter=4000,\n",
      "      normalize=False, random_state=None, solver='saga', tol=0.001)\n",
      "95% confindence interval:\n",
      "r2_score: 0.99951 (+/- 0.00003)\n",
      "MSE: 0.07888 (+/- 0.00543)\n",
      "MAE: 0.21718 (+/- 0.00451)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: Lasso(alpha=0.0038, copy_X=True, fit_intercept=True, max_iter=4000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "95% confindence interval:\n",
      "r2_score: 0.99931 (+/- 0.00009)\n",
      "MSE: 0.11186 (+/- 0.01135)\n",
      "MAE: 0.25714 (+/- 0.00729)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=7,\n",
      "                      min_samples_split=7, min_weight_fraction_leaf=0.000516,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "95% confindence interval:\n",
      "r2_score: 0.99949 (+/- 0.00003)\n",
      "MSE: 0.08355 (+/- 0.00608)\n",
      "MAE: 0.22493 (+/- 0.00619)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: XGBRegressor(alpha=0.00244, base_score=0.5, booster='dart', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, eta=0.017326,\n",
      "             gamma=0.19504, importance_type='gain', learning_rate=0.1,\n",
      "             max_delta_step=0, max_depth=8, min_child_weight=1, missing=None,\n",
      "             n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
      "             random_state=0, reg_alpha=0, reg_lambda=0.22451,\n",
      "             scale_pos_weight=1, seed=None, silent=None, subsample=1,\n",
      "             verbosity=0)\n",
      "95% confindence interval:\n",
      "r2_score: 0.99952 (+/- 0.00002)\n",
      "MSE: 0.07736 (+/- 0.00448)\n",
      "MAE: 0.21608 (+/- 0.00506)\n",
      "\n",
      "----------------------------\n",
      "Metaregressor: PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,\n",
      "                           epsilon=0.1, fit_intercept=True,\n",
      "                           loss='epsilon_insensitive', max_iter=3600,\n",
      "                           n_iter_no_change=5, random_state=None, shuffle=True,\n",
      "                           tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "95% confindence interval:\n",
      "r2_score: 0.99853 (+/- 0.00137)\n",
      "MSE: 0.23653 (+/- 0.21026)\n",
      "MAE: 0.38086 (+/- 0.19428)\n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for model in models:    \n",
    "    print(\"Metaregressor:\", model)\n",
    "    stregr = StackingRegressor(regressors=models, meta_regressor=model)\n",
    "    scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "    scores = cross_validate(stregr, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "    print(\"95% confindence interval:\")\n",
    "    print(\"r2_score: %0.5f (+/- %0.5f)\" % (scores['test_r2'].mean(), scores['test_r2'].std() * 2))\n",
    "    print(\"MSE: %0.5f (+/- %0.5f)\" % (-scores['test_neg_mean_squared_error'].mean(), scores['test_neg_mean_squared_error'].std() * 2))\n",
    "    print(\"MAE: %0.5f (+/- %0.5f)\" % (-scores['test_neg_mean_absolute_error'].mean(), scores['test_neg_mean_absolute_error'].std() * 2))\n",
    "    print()\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### As we can see the best r2_score 0.99952 achieves if using huber regressor as metamodel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
