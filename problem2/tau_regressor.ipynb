{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    file = open('./data/shashlik_61_pulses.txt', 'r')\n",
    "    data = file.readlines()\n",
    "    data = np.array([list(map(float, experiment.split())) for experiment in data])\n",
    "   \n",
    "    X = data[:, 2:]\n",
    "    y_baseline = data[:, 1]\n",
    "    y = data[:, 0]\n",
    "    \n",
    "    \n",
    "    X = np.array([experiment - np.max(experiment) for experiment in X])\n",
    "    X = np.array([experiment/-np.min(experiment) for experiment in X])\n",
    "\n",
    "    y = np.round(y)\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    ## Let's shift each signal so that reference time matches for each signal\n",
    "    mean_ref_time = int(y.mean())\n",
    "    X = np.array([signal_cyclic_shift(signal, mean_ref_time - y[i]) for i, signal in enumerate(X, 0)])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def get_freq_data(X, freq=1, start_point=384):\n",
    "    X_freq = np.concatenate([X[:, start_point::-freq][:, ::-1], X[:, start_point + freq::freq]], axis=1)\n",
    "    return X_freq\n",
    "\n",
    "def signal_cyclic_shift(signal, tau):\n",
    "    signal_start = signal[:-tau]\n",
    "    \n",
    "    new_signal = np.concatenate([signal[-tau:], signal_start])\n",
    "    \n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_origin, y_origin = get_data()\n",
    "\n",
    "mean_argmin =  int(np.argmin(X_origin, axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_multi_signal(X_origin, tau, alpha, to_plot=False):\n",
    "    first_idx, second_idx = np.random.choice(X_origin.shape[0], 2, replace=False)\n",
    "    first_impulse = X_origin[first_idx]\n",
    "    second_impulse = X_origin[second_idx]\n",
    "    \n",
    "    \n",
    "    ### Randomly choose what signal to shift\n",
    "    if random.choice([True, False]):\n",
    "        first_impulse = signal_cyclic_shift(first_impulse, tau)\n",
    "    else:\n",
    "        second_impulse = signal_cyclic_shift(second_impulse, tau)\n",
    "    \n",
    "    \n",
    "    multi_impulse = first_impulse + second_impulse*alpha\n",
    "    multi_impulse /= -np.min(multi_impulse)\n",
    "    \n",
    "    first_impulse_shifted = signal_cyclic_shift(first_impulse, mean_argmin - np.argmin(first_impulse))\n",
    "    second_impulse_shifted = signal_cyclic_shift(second_impulse, mean_argmin - np.argmin(second_impulse))\n",
    "    multi_impulse_shifted = signal_cyclic_shift(multi_impulse, mean_argmin - np.argmin(multi_impulse))\n",
    "\n",
    "    if to_plot:\n",
    "        plt.plot(first_impulse_shifted)\n",
    "        plt.plot(second_impulse_shifted)\n",
    "        plt.plot(multi_impulse_shifted)\n",
    "        plt.legend(['First signal', 'Second signal', 'Sum of signals'])\n",
    "        plt.show()\n",
    "        \n",
    "    return {'first': first_impulse_shifted,\\\n",
    "            'second': second_impulse_shifted,\\\n",
    "            'multi': multi_impulse_shifted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_data(X_origin, tau_range, alpha_range, data_size=1000, to_print=False):    \n",
    "    X = []\n",
    "    y = []\n",
    "    alpha_values = []\n",
    "    tau_values = []\n",
    "    for i in range(data_size):\n",
    "        alpha = random.choice(alpha_range)\n",
    "        tau = random.choice(tau_range)\n",
    "        signal = generate_multi_signal(X_origin, tau, alpha)['multi']\n",
    "        \n",
    "        X.append(signal)\n",
    "        y.append(tau)\n",
    "        \n",
    "        alpha_values.append(alpha)\n",
    "        tau_values.append(tau)\n",
    "   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if to_print:\n",
    "        print(\"X shape:\", X.shape)\n",
    "        print(\"y shape:\", y.shape)\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "#     plt.scatter(alpha_values, tau_values)\n",
    "#     plt.show()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_range = np.array([np.around(10**i, decimals=4) for i in np.arange(0, 3.1, 0.01)])\n",
    "\n",
    "alpha_range = np.arange(1, 100, 0.1)\n",
    "tau_range = np.arange(-100, 101, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (7848, 1024)\n",
      "y shape: (7848,)\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_data(X_origin, tau_range, alpha_range, data_size=len(X_origin), to_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([813., 760., 806., 780., 748., 760., 846., 756., 752., 827.]),\n",
       " array([-100.,  -80.,  -60.,  -40.,  -20.,    0.,   20.,   40.,   60.,\n",
       "          80.,  100.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores():\n",
    "    for model in models:    \n",
    "        model_name = type(model).__name__\n",
    "        print(\"Regressor:\", model_name)\n",
    "    #         stregr = StackingRegressor(regressors=models, meta_regressor=model)\n",
    "        scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "        scores = cross_validate(model, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "        r2_score_mean = scores['test_r2'].mean()\n",
    "        r2_score_std = scores['test_r2'].std()\n",
    "        mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "        mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "        mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "        mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "        rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "        rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "        cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                          (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "        print(\"95% confidence interval:\")\n",
    "        for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "            print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "        print('----------------------------------')\n",
    "    print('____________________________________________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    huber_reg = HuberRegressor(epsilon= 4.927, alpha= 0.00759)\n",
    "    ridge_reg = linear_model.Ridge(solver='saga', max_iter=5000, alpha= 1)\n",
    "    lasso_reg = linear_model.Lasso(max_iter=4400, alpha=0.69, normalize=False)\n",
    "    dt_reg = tree.DecisionTreeRegressor(min_samples_split=7, min_samples_leaf=9, min_weight_fraction_leaf=0.1, \n",
    "                                                                                                 max_features='sqrt')\n",
    "\n",
    "    pa_reg = PassiveAggressiveRegressor(C=0.44, max_iter=2800, tol=2.4e-5)\n",
    "    xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", alpha= 0.01, booster='gbtree', eta= 0.323, gamma=0.189, \n",
    "                               reg_lambda=0.48, max_depth=6, verbosity=0)\n",
    "    return [huber_reg, ridge_reg, lasso_reg, dt_reg,  pa_reg, xgb_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor: HuberRegressor\n",
      "95% confidence interval:\n",
      "r2 score: -0.00646 (+/- 0.00778)\n",
      "mse score: 3406.62429 (+/- 77.74413)\n",
      "mae score: 50.57222 (+/- 0.73550)\n",
      "rmse score: 58.36534 (+/- 0.66618)\n",
      "----------------------------------\n",
      "Regressor: Ridge\n",
      "95% confidence interval:\n",
      "r2 score: -0.00543 (+/- 0.00852)\n",
      "mse score: 3403.15247 (+/- 79.91214)\n",
      "mae score: 50.56152 (+/- 0.76240)\n",
      "rmse score: 58.33554 (+/- 0.68513)\n",
      "----------------------------------\n",
      "Regressor: Lasso\n",
      "95% confidence interval:\n",
      "r2 score: -0.00068 (+/- 0.00087)\n",
      "mse score: 3387.05294 (+/- 71.39725)\n",
      "mae score: 50.49884 (+/- 0.75400)\n",
      "rmse score: 58.19758 (+/- 0.61353)\n",
      "----------------------------------\n",
      "Regressor: DecisionTreeRegressor\n",
      "95% confidence interval:\n",
      "r2 score: -0.01383 (+/- 0.00922)\n",
      "mse score: 3431.52480 (+/- 73.36814)\n",
      "mae score: 50.70410 (+/- 0.70756)\n",
      "rmse score: 58.57838 (+/- 0.62741)\n",
      "----------------------------------\n",
      "Regressor: PassiveAggressiveRegressor\n",
      "95% confidence interval:\n",
      "r2 score: -0.43052 (+/- 0.72304)\n",
      "mse score: 4835.58406 (+/- 2370.30176)\n",
      "mae score: 57.51147 (+/- 11.90933)\n",
      "rmse score: 69.06814 (+/- 16.14629)\n",
      "----------------------------------\n",
      "Regressor: XGBRegressor\n",
      "95% confidence interval:\n",
      "r2 score: -0.06947 (+/- 0.02559)\n",
      "mse score: 3619.62039 (+/- 77.23890)\n",
      "mae score: 50.93743 (+/- 0.59398)\n",
      "rmse score: 60.16243 (+/- 0.64073)\n",
      "----------------------------------\n",
      "____________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaregressor: HuberRegressor\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d2405407fa3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_regressor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstregr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mr2_score_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_r2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 231\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mlxtend/regressor/stacking_regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    models = get_models()\n",
    "    print(\"Metaregressor:\", type(models[i]).__name__)\n",
    "\n",
    "    stregr = StackingRegressor(regressors=models, meta_regressor=models[i])\n",
    "    scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "    scores = cross_validate(stregr, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "    r2_score_mean = scores['test_r2'].mean()\n",
    "    r2_score_std = scores['test_r2'].std()\n",
    "    mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "    mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "    mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "    mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "    rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "    rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "    cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                      (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "    print(\"95% confindence interval:\")\n",
    "    for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "        print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "    print('--------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
