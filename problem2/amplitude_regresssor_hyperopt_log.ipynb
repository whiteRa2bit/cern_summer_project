{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt.pyll import scope as ho_scope\n",
    "from hyperopt import fmin, tpe, hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_data, get_freq_data, signal_cyclic_shift, generate_multi_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_origin, y_origin = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_data(X_origin, y_origin, tau_range, alpha_range, data_size=1000, to_print=False):    \n",
    "    X = []\n",
    "    y = []\n",
    "    alpha_values = []\n",
    "    tau_values = []\n",
    "    for i in range(data_size):\n",
    "        alpha = random.choice(alpha_range)\n",
    "        tau = random.choice(tau_range)\n",
    "        signal = generate_multi_signal(X_origin, y_origin, tau, alpha)['multi_impulse']\n",
    "        \n",
    "        X.append(signal)\n",
    "        y.append(np.log10(alpha))\n",
    "        \n",
    "        alpha_values.append(alpha)\n",
    "        tau_values.append(tau)\n",
    "   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if to_print:\n",
    "        print(\"X shape:\", X.shape)\n",
    "        print(\"y shape:\", y.shape)\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "#     plt.scatter(alpha_values, tau_values)\n",
    "#     plt.show()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_range = np.array([np.around(10**i, decimals=4) for i in np.arange(0, 3.1, 0.01)])\n",
    "# alpha_range = np.arange(1, 1000, 0.1)\n",
    "alpha_range = np.array([10**i for i in np.arange(0, 3, 0.05)])\n",
    "tau_range = np.arange(-25, 25, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (500, 1024)\n",
      "y shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_data(X_origin, y_origin, tau_range, alpha_range, data_size=500, to_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_values = [1, 5, 10, 15, 25, 50, 60, 75, 85, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(iter_num=200):\n",
    "    global X_freq\n",
    "    for freq in freq_values:\n",
    "        X_freq = get_freq_data(X, freq=freq)\n",
    "\n",
    "        best = fmin(\n",
    "            fn=f,  # \"Loss\" function to minimize\n",
    "            space=space,  # Hyperparameter space\n",
    "            algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "            max_evals=iter_num  # Perform 100 trials\n",
    "        )\n",
    "\n",
    "        print('-----------------------------------------------------')\n",
    "        print(\"Freq:\", freq)\n",
    "        print(\"X_freq shape:\", X_freq.shape)\n",
    "        print(\"Found minimum after %d trials:\" %(iter_num))\n",
    "        print(best)\n",
    "        print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [09:39<00:00,  2.90s/it, best loss: 0.6001469249942125]\n",
      "-----------------------------------------------------\n",
      "Freq: 1\n",
      "X_freq shape: (500, 1024)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.0008862233649182545, 'epsilon': 3.522881623454345, 'max_iter': 130.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [04:22<00:00,  1.31s/it, best loss: 0.5928062870246442]\n",
      "-----------------------------------------------------\n",
      "Freq: 5\n",
      "X_freq shape: (500, 204)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.009814954503151637, 'epsilon': 2.8822182873563125, 'max_iter': 100.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [04:02<00:00,  1.21s/it, best loss: 0.5939124798484652]\n",
      "-----------------------------------------------------\n",
      "Freq: 10\n",
      "X_freq shape: (500, 102)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.009944063913603498, 'epsilon': 3.7685773623301952, 'max_iter': 310.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [03:40<00:00,  1.10s/it, best loss: 0.5950467153846077]\n",
      "-----------------------------------------------------\n",
      "Freq: 15\n",
      "X_freq shape: (500, 68)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.009972960551403221, 'epsilon': 1.1040220191398606, 'max_iter': 290.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [03:05<00:00,  1.08it/s, best loss: 0.6002679070499577]\n",
      "-----------------------------------------------------\n",
      "Freq: 25\n",
      "X_freq shape: (500, 41)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.009997664094894927, 'epsilon': 8.167455169159743, 'max_iter': 430.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:43<00:00,  4.64it/s, best loss: 0.6579643268703592]\n",
      "-----------------------------------------------------\n",
      "Freq: 50\n",
      "X_freq shape: (500, 20)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.007258595747834435, 'epsilon': 4.333884364105326, 'max_iter': 430.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:41<00:00,  4.85it/s, best loss: 0.6690781412443355]\n",
      "-----------------------------------------------------\n",
      "Freq: 60\n",
      "X_freq shape: (500, 17)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.007852835241956718, 'epsilon': 1.102230132937116, 'max_iter': 370.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:37<00:00,  5.35it/s, best loss: 0.6816112396391371]\n",
      "-----------------------------------------------------\n",
      "Freq: 75\n",
      "X_freq shape: (500, 14)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.005773037660806321, 'epsilon': 7.7062579580302835, 'max_iter': 440.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:30<00:00,  6.47it/s, best loss: 0.6875689159578118]\n",
      "-----------------------------------------------------\n",
      "Freq: 85\n",
      "X_freq shape: (500, 12)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.00037984132176500864, 'epsilon': 6.0172639829003405, 'max_iter': 110.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:19<00:00, 10.06it/s, best loss: 0.7073667316885264]\n",
      "-----------------------------------------------------\n",
      "Freq: 100\n",
      "X_freq shape: (500, 10)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.009988542118571225, 'epsilon': 7.054192908907026, 'max_iter': 170.0}\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    huber_reg = HuberRegressor(epsilon=space['epsilon'], max_iter=space['max_iter'], alpha=space['alpha'])\n",
    "    scores = cross_validate(huber_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'epsilon':  hp.loguniform('epsilon', low=np.log(1.1), high=np.log(10)),\n",
    "    'max_iter': ho_scope.int(hp.quniform('max_iter', low=100, high=500, q=10)),\n",
    "    'alpha':  hp.loguniform('alpha', low=np.log(0.0001), high=np.log(0.01)),\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [07:06<00:00,  2.13s/it, best loss: 0.5932825667494368]\n",
      "-----------------------------------------------------\n",
      "Freq: 1\n",
      "X_freq shape: (500, 1024)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.17055124503981708, 'max_iter': 4000.0, 'solver': 3}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [01:14<00:00,  2.67it/s, best loss: 0.5916921617802513]\n",
      "-----------------------------------------------------\n",
      "Freq: 5\n",
      "X_freq shape: (500, 204)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.035595843222584585, 'max_iter': 1600.0, 'solver': 3}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [01:43<00:00,  1.93it/s, best loss: 0.5928987250176619]\n",
      "-----------------------------------------------------\n",
      "Freq: 10\n",
      "X_freq shape: (500, 102)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.013167811954036572, 'max_iter': 3500.0, 'solver': 6}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [01:08<00:00,  2.94it/s, best loss: 0.5951583026234332]\n",
      "-----------------------------------------------------\n",
      "Freq: 15\n",
      "X_freq shape: (500, 68)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.01009235974911529, 'max_iter': 3500.0, 'solver': 6}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:25<00:00,  7.75it/s, best loss: 0.5991771929839819]\n",
      "-----------------------------------------------------\n",
      "Freq: 25\n",
      "X_freq shape: (500, 41)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.012430310980440958, 'max_iter': 1600.0, 'solver': 3}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:17<00:00, 11.42it/s, best loss: 0.6580300910882823]\n",
      "-----------------------------------------------------\n",
      "Freq: 50\n",
      "X_freq shape: (500, 20)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.005779513688043248, 'max_iter': 2800.0, 'solver': 5}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:14<00:00, 13.58it/s, best loss: 0.6699872843099601]\n",
      "-----------------------------------------------------\n",
      "Freq: 60\n",
      "X_freq shape: (500, 17)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.007341210380029812, 'max_iter': 3100.0, 'solver': 6}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:07<00:00, 27.96it/s, best loss: 0.6816239290752721]\n",
      "-----------------------------------------------------\n",
      "Freq: 75\n",
      "X_freq shape: (500, 14)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.004486490967888213, 'max_iter': 1300.0, 'solver': 3}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:06<00:00, 30.82it/s, best loss: 0.6872587587378047]\n",
      "-----------------------------------------------------\n",
      "Freq: 85\n",
      "X_freq shape: (500, 12)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.00010024533223941237, 'max_iter': 2300.0, 'solver': 3}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:04<00:00, 42.22it/s, best loss: 0.7060495413455702]\n",
      "-----------------------------------------------------\n",
      "Freq: 100\n",
      "X_freq shape: (500, 10)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.9956770472735442, 'max_iter': 4600.0, 'solver': 0}\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    ridge_reg = linear_model.Ridge(solver=space['solver'], max_iter=space['max_iter'], alpha=space['alpha'])\n",
    "    scores = cross_validate(ridge_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'solver': hp.choice('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']),\n",
    "    'max_iter': ho_scope.int(hp.quniform('max_iter', low=1000, high=5000, q=100)),\n",
    "    'alpha':  hp.loguniform('alpha', low=np.log(0.0001), high=np.log(1)),\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [06:18<00:00,  1.89s/it, best loss: 0.5925920299258463]\n",
      "-----------------------------------------------------\n",
      "Freq: 1\n",
      "X_freq shape: (500, 1024)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.00026565972749035015, 'max_iter': 5000.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [02:07<00:00,  1.57it/s, best loss: 0.5927638511218996]\n",
      "-----------------------------------------------------\n",
      "Freq: 5\n",
      "X_freq shape: (500, 204)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.000323089195263108, 'max_iter': 4700.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [01:08<00:00,  2.94it/s, best loss: 0.5938024216629183]\n",
      "-----------------------------------------------------\n",
      "Freq: 10\n",
      "X_freq shape: (500, 102)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.00033959845544862986, 'max_iter': 2100.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:37<00:00,  5.36it/s, best loss: 0.5954001077761488]\n",
      "-----------------------------------------------------\n",
      "Freq: 15\n",
      "X_freq shape: (500, 68)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.0001959023232496914, 'max_iter': 2800.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:23<00:00,  8.69it/s, best loss: 0.6011234255204668]\n",
      "-----------------------------------------------------\n",
      "Freq: 25\n",
      "X_freq shape: (500, 41)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.00018304753563496928, 'max_iter': 4600.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:04<00:00, 40.24it/s, best loss: 0.6557944918712889]\n",
      "-----------------------------------------------------\n",
      "Freq: 50\n",
      "X_freq shape: (500, 20)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.00010534035480414255, 'max_iter': 3100.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:04<00:00, 47.26it/s, best loss: 0.6692808950282659]\n",
      "-----------------------------------------------------\n",
      "Freq: 60\n",
      "X_freq shape: (500, 17)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.00020528757823498554, 'max_iter': 2800.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:04<00:00, 47.59it/s, best loss: 0.6805965660611031]\n",
      "-----------------------------------------------------\n",
      "Freq: 75\n",
      "X_freq shape: (500, 14)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.0001002716503995456, 'max_iter': 4600.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:03<00:00, 51.14it/s, best loss: 0.6891706151735448]\n",
      "-----------------------------------------------------\n",
      "Freq: 85\n",
      "X_freq shape: (500, 12)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.00010005738529896149, 'max_iter': 4600.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:03<00:00, 55.59it/s, best loss: 0.7044455000000001]\n",
      "-----------------------------------------------------\n",
      "Freq: 100\n",
      "X_freq shape: (500, 10)\n",
      "Found minimum after 200 trials:\n",
      "{'alpha': 0.01574942158177157, 'max_iter': 5000.0, 'normalize': 1}\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    lasso_reg = linear_model.Lasso(max_iter=space['max_iter'], alpha=space['alpha'], normalize=space['normalize'])\n",
    "    scores = cross_validate(lasso_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'normalize': hp.choice('normalize', [True, False]),\n",
    "    'max_iter': ho_scope.int(hp.quniform('max_iter', low=1000, high=5000, q=100)),\n",
    "    'alpha':  hp.loguniform('alpha', low=np.log(0.0001), high=np.log(1)),\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:29<00:00,  6.80it/s, best loss: 0.6976033616734909]\n",
      "-----------------------------------------------------\n",
      "Freq: 1\n",
      "X_freq shape: (500, 1024)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 0, 'max_iter': 38.0, 'min_samples_leaf': 5.0, 'min_samples_split': 10.0, 'min_weight_fraction_leaf': 0.32584947432607825}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:12<00:00, 16.27it/s, best loss: 0.6974829980289179]\n",
      "-----------------------------------------------------\n",
      "Freq: 5\n",
      "X_freq shape: (500, 204)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 0, 'max_iter': 62.0, 'min_samples_leaf': 7.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.34579871962115427}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:09<00:00, 21.15it/s, best loss: 0.6974829980289179]\n",
      "-----------------------------------------------------\n",
      "Freq: 10\n",
      "X_freq shape: (500, 102)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 0, 'max_iter': 30.0, 'min_samples_leaf': 8.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.3331106831156331}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:08<00:00, 24.15it/s, best loss: 0.6966847590972768]\n",
      "-----------------------------------------------------\n",
      "Freq: 15\n",
      "X_freq shape: (500, 68)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 0, 'max_iter': 88.0, 'min_samples_leaf': 6.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.48662377275548263}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:06<00:00, 30.04it/s, best loss: 0.6987465489183812]\n",
      "-----------------------------------------------------\n",
      "Freq: 25\n",
      "X_freq shape: (500, 41)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 1, 'max_iter': 44.0, 'min_samples_leaf': 7.0, 'min_samples_split': 8.0, 'min_weight_fraction_leaf': 0.0987545541034899}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:06<00:00, 31.18it/s, best loss: 0.7011259383757216]\n",
      "-----------------------------------------------------\n",
      "Freq: 50\n",
      "X_freq shape: (500, 20)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 1, 'max_iter': 82.0, 'min_samples_leaf': 3.0, 'min_samples_split': 2.0, 'min_weight_fraction_leaf': 0.2209784686122852}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:06<00:00, 30.93it/s, best loss: 0.6995298849546684]\n",
      "-----------------------------------------------------\n",
      "Freq: 60\n",
      "X_freq shape: (500, 17)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 2, 'max_iter': 8.0, 'min_samples_leaf': 5.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.24234460919384104}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:06<00:00, 33.05it/s, best loss: 0.7018492046432032]\n",
      "-----------------------------------------------------\n",
      "Freq: 75\n",
      "X_freq shape: (500, 14)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 1, 'max_iter': 44.0, 'min_samples_leaf': 5.0, 'min_samples_split': 2.0, 'min_weight_fraction_leaf': 0.35514480661881087}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:06<00:00, 32.19it/s, best loss: 0.6937733534787528]\n",
      "-----------------------------------------------------\n",
      "Freq: 85\n",
      "X_freq shape: (500, 12)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 2, 'max_iter': 26.0, 'min_samples_leaf': 8.0, 'min_samples_split': 4.0, 'min_weight_fraction_leaf': 0.27359691239809786}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:06<00:00, 31.96it/s, best loss: 0.6976996171863604]\n",
      "-----------------------------------------------------\n",
      "Freq: 100\n",
      "X_freq shape: (500, 10)\n",
      "Found minimum after 200 trials:\n",
      "{'max_features': 1, 'max_iter': 28.0, 'min_samples_leaf': 6.0, 'min_samples_split': 6.0, 'min_weight_fraction_leaf': 0.17633078944015845}\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    dt_reg = tree.DecisionTreeRegressor(max_depth=space['max_depth'], min_samples_split=space['min_samples_split'],\n",
    "                                       min_samples_leaf=space['min_samples_leaf'], min_weight_fraction_leaf=\n",
    "                                        space['min_weight_fraction_leaf'], max_features=space['max_features'])\n",
    "    scores = cross_validate(dt_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'max_depth':  ho_scope.int(hp.quniform('max_iter', low=4, high=100, q=2)),\n",
    "    'min_samples_split': ho_scope.int(hp.quniform('min_samples_split', low=2, high=10, q=1)),\n",
    "    'min_samples_leaf':  ho_scope.int(hp.quniform('min_samples_leaf', low=1, high=10, q=1)),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0, 0.5),\n",
    "    'max_features': hp.choice('max_features', ['auto', 'sqrt', 'log2'])\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passive aggresive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:20<00:00,  9.94it/s, best loss: 0.7059047889381511]\n",
      "-----------------------------------------------------\n",
      "Freq: 1\n",
      "X_freq shape: (500, 1024)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.0005118513041847099, 'max_iter': 3400.0, 'tol': 5.468543150798296e-06, 'verbose': 78.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:10<00:00, 19.99it/s, best loss: 0.7055752831433362]\n",
      "-----------------------------------------------------\n",
      "Freq: 5\n",
      "X_freq shape: (500, 204)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.001123685263491527, 'max_iter': 2100.0, 'tol': 2.872641304840765e-06, 'verbose': 82.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:08<00:00, 23.77it/s, best loss: 0.7051924669603904]\n",
      "-----------------------------------------------------\n",
      "Freq: 10\n",
      "X_freq shape: (500, 102)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.0026257015811204975, 'max_iter': 4400.0, 'tol': 1.8183423455195677e-06, 'verbose': 98.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:05<00:00, 34.84it/s, best loss: 0.7065018996220097]\n",
      "-----------------------------------------------------\n",
      "Freq: 15\n",
      "X_freq shape: (500, 68)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.0034243978340695517, 'max_iter': 3100.0, 'tol': 0.0005636142142693609, 'verbose': 18.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:05<00:00, 36.74it/s, best loss: 0.7036309220551307]\n",
      "-----------------------------------------------------\n",
      "Freq: 25\n",
      "X_freq shape: (500, 41)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.018040140540129018, 'max_iter': 3900.0, 'tol': 1.706147200352028e-05, 'verbose': 72.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:05<00:00, 37.45it/s, best loss: 0.7016287015892841]\n",
      "-----------------------------------------------------\n",
      "Freq: 50\n",
      "X_freq shape: (500, 20)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.012163364107356021, 'max_iter': 3200.0, 'tol': 3.5149736998299505e-05, 'verbose': 24.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:05<00:00, 36.86it/s, best loss: 0.7006893370459325]\n",
      "-----------------------------------------------------\n",
      "Freq: 60\n",
      "X_freq shape: (500, 17)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.07312050753097188, 'max_iter': 1200.0, 'tol': 5.992414133286319e-06, 'verbose': 38.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:05<00:00, 37.04it/s, best loss: 0.7029117764072156]\n",
      "-----------------------------------------------------\n",
      "Freq: 75\n",
      "X_freq shape: (500, 14)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.006914328631244094, 'max_iter': 3700.0, 'tol': 0.00020664541884785688, 'verbose': 18.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:05<00:00, 37.92it/s, best loss: 0.7026907351056875]\n",
      "-----------------------------------------------------\n",
      "Freq: 85\n",
      "X_freq shape: (500, 12)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.002888435037991841, 'max_iter': 1800.0, 'tol': 0.00013370669277927802, 'verbose': 52.0}\n",
      "-----------------------------------------------------\n",
      "100%|██████████| 200/200 [00:05<00:00, 38.68it/s, best loss: 0.7028740611181394]\n",
      "-----------------------------------------------------\n",
      "Freq: 100\n",
      "X_freq shape: (500, 10)\n",
      "Found minimum after 200 trials:\n",
      "{'c': 0.005692776028965883, 'max_iter': 2900.0, 'tol': 6.2582354161251764e-06, 'verbose': 64.0}\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    pa_reg = PassiveAggressiveRegressor(max_iter=space['max_iter'], tol=space['max_iter'], \n",
    "                                       C = space['C'])\n",
    "    scores = cross_validate(pa_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'max_iter': ho_scope.int(hp.quniform('max_iter', low=1000, high=5000, q=100)),\n",
    "    'tol': hp.loguniform('tol', low=np.log(0.000001), high=np.log(0.001)),\n",
    "    'verbose': ho_scope.int(hp.quniform('verbose', low=1, high=100, q=2)),\n",
    "    'C':  hp.loguniform('c', low=np.log(0.0001), high=np.log(10)),\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [45:38<25:30, 43.74s/it, best loss: 0.6649719057321549]  "
     ]
    }
   ],
   "source": [
    "def f(space):\n",
    "    xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", booster=space['booster'], eta=space['eta'], \n",
    "                               gamma=space['gamma'], max_depth=space['max_depth'], reg_lambda=space['lambda'],\n",
    "                               alpha=space['alpha'], verbosity=0)\n",
    "    scores = cross_validate(xgb_reg, X_freq, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "    return -scores['test_score'].mean()\n",
    "    \n",
    "space = {\n",
    "    'booster': hp.choice('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "    'eta': hp.loguniform('eta', low=np.log(0.001), high=np.log(1)),\n",
    "    'gamma': hp.loguniform('gamma', low=np.log(0.001), high=np.log(100)),\n",
    "    'max_depth': ho_scope.int(hp.quniform('max_depth', low=5, high=50, q=2)),\n",
    "    'lambda': hp.loguniform('lambda', low=np.log(0.001), high=np.log(10)),\n",
    "    'alpha':  hp.loguniform('alpha', low=np.log(0.001), high=np.log(10)),\n",
    "}\n",
    "\n",
    "global X_freq\n",
    "print_results(iter_num=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
