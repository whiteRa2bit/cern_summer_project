{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    file = open('./data/shashlik_61_pulses.txt', 'r')\n",
    "    data = file.readlines()\n",
    "    data = np.array([list(map(float, experiment.split())) for experiment in data])\n",
    "   \n",
    "    X = data[:, 2:]\n",
    "    y_baseline = data[:, 1]\n",
    "    y = data[:, 0]\n",
    "    \n",
    "    \n",
    "    X = np.array([experiment - np.max(experiment) for experiment in X])\n",
    "    X = np.array([experiment/-np.min(experiment) for experiment in X])\n",
    "\n",
    "    y = np.round(y)\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    ## Let's shift each signal so that reference time matches for each signal\n",
    "    mean_ref_time = int(y.mean())\n",
    "    X = np.array([signal_cyclic_shift(signal, mean_ref_time - y[i]) for i, signal in enumerate(X, 0)])\n",
    "    y = np.array([mean_ref_time]*len(y))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def get_freq_data(X, freq=1, start_point=384):\n",
    "    X_freq = np.concatenate([X[:, start_point::-freq][:, ::-1], X[:, start_point + freq::freq]], axis=1)\n",
    "    return X_freq\n",
    "\n",
    "def signal_cyclic_shift(signal, tau):\n",
    "    signal_start = signal[:-tau]\n",
    "    \n",
    "    new_signal = np.concatenate([signal[-tau:], signal_start])\n",
    "    \n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_origin, y_origin = get_data()\n",
    "\n",
    "mean_argmin =  int(np.argmin(X_origin, axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_time(first_impulse, second_impulse, first_ref_time, second_ref_time):\n",
    "    if np.min(first_impulse) < np.min(second_impulse):\n",
    "         return first_ref_time\n",
    "    else:\n",
    "        return second_ref_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ARGMIN_DISTR_LEN = 60\n",
    "\n",
    "def generate_multi_signal(X_origin, y_origin, tau, alpha, to_plot=False):\n",
    "    first_idx, second_idx = np.random.choice(X_origin.shape[0], 2, replace=False)\n",
    "    first_impulse = X_origin[first_idx]\n",
    "    second_impulse = X_origin[second_idx]\n",
    "    \n",
    "    first_ref_time = y_origin[first_idx]\n",
    "    second_ref_time = y_origin[second_idx]\n",
    "    \n",
    "    \n",
    "#     print(\"SHIFT:\", tau)\n",
    "#     print(\"BEFORE SHIFT:\", first_ref_time, second_ref_time)\n",
    "    ### Randomly choose what signal to shift\n",
    "#     if random.choice([True, False]):\n",
    "#         first_impulse = signal_cyclic_shift(first_impulse, tau)\n",
    "#         first_ref_time += tau\n",
    "#     else:\n",
    "#         second_impulse = signal_cyclic_shift(second_impulse, tau)\n",
    "#         second_ref_time += tau\n",
    "    second_impulse = signal_cyclic_shift(second_impulse, tau)\n",
    "    second_ref_time += tau\n",
    "    \n",
    "#     print(\"AFTER SHIFT:\", first_ref_time, second_ref_time)\n",
    "    \n",
    "    multi_impulse = first_impulse + second_impulse*alpha\n",
    "    multi_impulse /= -np.min(multi_impulse)\n",
    "    \n",
    "    new_pos = mean_argmin + random.choice(range(-int(ARGMIN_DISTR_LEN/2), int(ARGMIN_DISTR_LEN/2), 1))\n",
    "    first_impulse_shifted = signal_cyclic_shift(first_impulse, new_pos - np.argmin(first_impulse))\n",
    "    second_impulse_shifted = signal_cyclic_shift(second_impulse, new_pos - np.argmin(second_impulse))\n",
    "    multi_impulse_shifted = signal_cyclic_shift(multi_impulse, new_pos - np.argmin(multi_impulse))\n",
    "\n",
    "#     print(mean_argmin - np.argmin(multi_impulse))\n",
    "    first_ref_time +=  mean_argmin - np.argmin(multi_impulse)\n",
    "    second_ref_time +=  mean_argmin - np.argmin(multi_impulse)\n",
    "    \n",
    "    if to_plot:\n",
    "        plt.plot(first_impulse)\n",
    "        plt.plot(second_impulse)\n",
    "        plt.plot(multi_impulse_shifted)\n",
    "        plt.legend(['First signal', 'Second signal', 'Sum of signals'])\n",
    "        plt.show()\n",
    "        \n",
    "    ref_time = get_ref_time(first_impulse, second_impulse*alpha, first_ref_time, second_ref_time)\n",
    "    \n",
    "    return {'first_impulse': first_impulse_shifted,\\\n",
    "            'second_impulse': second_impulse_shifted,\\\n",
    "            'ref_time': ref_time,\\\n",
    "            'multi_impulse': multi_impulse_shifted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'range'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0b6dff40b9e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_multi_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-9a517a166202>\u001b[0m in \u001b[0;36mgenerate_multi_signal\u001b[0;34m(X_origin, y_origin, tau, alpha, to_plot)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmulti_impulse\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_impulse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mnew_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_argmin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mfirst_impulse_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_cyclic_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_impulse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_impulse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0msecond_impulse_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_cyclic_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond_impulse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond_impulse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'range'"
     ]
    }
   ],
   "source": [
    "generate_multi_signal(X_origin, y_origin, 100, 0.1, to_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_multi_signal(X_origin, y_origin, -100, 0.1, to_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_data(X_origin, y_origin, tau_range, alpha_range, data_size=1000, to_print=False):    \n",
    "    X = []\n",
    "    y = []\n",
    "    alpha_values = []\n",
    "    tau_values = []\n",
    "    for i in range(data_size):\n",
    "        alpha = random.choice(alpha_range)\n",
    "        tau = random.choice(tau_range)\n",
    "        signal = generate_multi_signal(X_origin, y_origin, tau, alpha)\n",
    "        \n",
    "        \n",
    "        X.append(signal['multi_impulse'])\n",
    "        y.append(signal['ref_time']) \n",
    "        \n",
    "        alpha_values.append(alpha)\n",
    "        tau_values.append(tau)\n",
    "   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if to_print:\n",
    "        print(\"X shape:\", X.shape)\n",
    "        print(\"y shape:\", y.shape)\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "#     plt.scatter(alpha_values, tau_values)\n",
    "#     plt.show()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_range = np.array([np.around(10**i, decimals=4) for i in np.arange(0, 3.1, 0.01)])\n",
    "\n",
    "# alpha_range = [10]\n",
    "# tau_range = [0]\n",
    "alpha_range = np.array([np.around(10**i, decimals=4) for i in np.arange(-3, 3.1, 0.1)])\n",
    "tau_range = np.arange(-100, 101, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(alpha_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = prepare_data(X_origin, y_origin, tau_range, alpha_range, data_size=5000, to_print=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = get_freq_data(X, freq=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Target distribution\")\n",
    "plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for i in range(len(y)):\n",
    "    if y[i] < 100:\n",
    "        idxs.append(i)\n",
    "        \n",
    "i = 3\n",
    "plt.title(\"Multiple impulse\")\n",
    "plt.plot(X[idxs[i]])\n",
    "print(\"Ref time:\", y[idxs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores():\n",
    "    for model in models.values():    \n",
    "        model_name = type(model).__name__\n",
    "        print(\"Regressor:\", model_name)\n",
    "    #         stregr = StackingRegressor(regressors=models, meta_regressor=model)\n",
    "        scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "        scores = cross_validate(model, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "        r2_score_mean = scores['test_r2'].mean()\n",
    "        r2_score_std = scores['test_r2'].std()\n",
    "        mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "        mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "        mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "        mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "        rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "        rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "        cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                          (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "        print(\"95% confidence interval:\")\n",
    "        for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "            print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "        print('----------------------------------')\n",
    "    print('____________________________________________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    huber_reg = HuberRegressor(epsilon= 1.242, alpha= 0.01)\n",
    "    ridge_reg = linear_model.Ridge(solver='lsqr', max_iter=4000, alpha=  0.513)\n",
    "    lasso_reg = linear_model.Lasso(max_iter=4400, alpha= 0.00849, normalize=False)\n",
    "    dt_reg = tree.DecisionTreeRegressor(min_samples_split=9, min_samples_leaf=9, min_weight_fraction_leaf=0.018, \n",
    "                                                                                                 max_features='auto')\n",
    "\n",
    "    pa_reg = PassiveAggressiveRegressor(C=0.44, max_iter=2800, tol=2.4e-5)\n",
    "    xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", alpha= 0.01, booster='gbtree', eta= 0.323, gamma=0.189, \n",
    "                               reg_lambda=0.48, max_depth=6, verbosity=0)\n",
    "    return {'huber': huber_reg, 'ridge': ridge_reg, 'lasso': lasso_reg, 'dt': dt_reg, 'pa':pa_reg, 'xgb': xgb_reg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    models = get_models()\n",
    "    del models['pa'] ### Delete passive agressive regressor, which performs poorly\n",
    "    \n",
    "    print(\"Metaregressor:\", type(model).__name__)\n",
    "\n",
    "    stregr = StackingRegressor(regressors=list(models.values()), meta_regressor=model)\n",
    "    scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "    scores = cross_validate(stregr, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "    r2_score_mean = scores['test_r2'].mean()\n",
    "    r2_score_std = scores['test_r2'].std()\n",
    "    mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "    mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "    mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "    mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "    rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "    rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "    cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                      (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "    print(\"95% confidence interval:\")\n",
    "    for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "        print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot regression scores for different frequency, tau and alpha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.array([np.around(10**i, decimals=4) for i in np.arange(-3, 3.1, 0.1)])\n",
    "tau_values = range(-100, 110, 5)\n",
    "freq_values = [1, 25, 50, 75, 100, 125, 150]\n",
    "TIME_SCALE_COEF = 0.2\n",
    "# alpha_values = np.around(np.arange(0, 100, 2), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(X_origin, y_orign, alpha_values, tau_values, data_size=100, freq=1):\n",
    "#     NORM_COEF = 50\n",
    "    scores_dict = {}\n",
    "    \n",
    "    \n",
    "    X, y = prepare_data(X_origin, y_origin, tau_values, alpha_values, to_print=False, data_size=int(len(X_origin)/4))\n",
    "#     model = StackingRegressor(regressors=list(models.values()), meta_regressor=models['huber'])\n",
    "    model = get_models()['xgb']\n",
    "    X_freq = get_freq_data(X, freq=freq)\n",
    "    model.fit(X_freq, y)\n",
    "\n",
    "    for tau in tqdm.tqdm(tau_values):\n",
    "        scores_dict[tau] = dict(zip(alpha_values, np.zeros(len(alpha_values))))\n",
    "        for alpha in alpha_values:\n",
    "            X_cur, y_cur = prepare_data(X_origin, y_origin, [tau], [alpha], data_size=data_size)\n",
    "            X_cur = get_freq_data(X_cur, freq=freq)\n",
    "            y_pred = model.predict(X_cur)\n",
    "\n",
    "            scores_dict[tau][alpha] = np.log10(sqrt(mean_squared_error(y_pred, y_cur))) #* TIME_SCALE_COEF\n",
    "\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_arrays(scores_dict):\n",
    "    x, y, z = [], [], []\n",
    "    for tau, alpha_dict in scores_dict.items():\n",
    "        for alpha, score in alpha_dict.items():\n",
    "            x.append(tau)\n",
    "            y.append(alpha)\n",
    "            z.append(score)\n",
    "            \n",
    "    return [x, y, z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('./data/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('./data/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "VMIN = -0.5\n",
    "VMAX = 2\n",
    "STEP = 0.25\n",
    "ORIGIN_FREQ = 5000\n",
    "\n",
    "def plot_color_map(scores_dict, alpha_values, tau_values, alpha_freq=10, tau_freq=4, freq=1):\n",
    "    _, _, z = dict_to_arrays(scores_dict)\n",
    "    z = np.array(z)\n",
    "    Z = z.reshape((len(tau_values), len(alpha_values)))\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    plt.title(\"log10(RMSE), frequency = \" + str(int(ORIGIN_FREQ/freq)) + ' [MHz]') \n",
    "    plt.xlabel(\"Two signals ratio\", fontsize=12)\n",
    "    plt.ylabel(\"Delta t [ns]\", fontsize=12)\n",
    "    plt.xticks([alpha_freq*i for i in range(len(alpha_values[::alpha_freq]))], alpha_values[::alpha_freq])\n",
    "    plt.yticks([tau_freq*i for i in range(len(tau_values[::tau_freq]))], [TIME_SCALE_COEF*el for el in tau_values[::tau_freq]])\n",
    "\n",
    "    im = ax.imshow(Z, interpolation='bilinear', cmap='spring', aspect='auto', vmin=VMIN, vmax=VMAX)\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.5)\n",
    "\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_ticks(np.arange(VMIN, VMAX, STEP))\n",
    "    cbar.set_ticklabels(np.arange(VMIN, VMAX, STEP))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for freq in freq_values:\n",
    "    X_origin, y_origin = get_data()\n",
    "    scores_dict = calculate_scores(X_origin, y_origin, alpha_values, tau_values, data_size=500, freq=freq)\n",
    "    plot_color_map(scores_dict, alpha_values, tau_values, freq=freq)\n",
    "    save_obj(scores_dict, 'scores_ref_time_freq=' + str(freq))\n",
    "#     plot_score_3d(scores_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
