{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    file = open('./data/shashlik_61_pulses.txt', 'r')\n",
    "    data = file.readlines()\n",
    "    data = np.array([list(map(float, experiment.split())) for experiment in data])\n",
    "   \n",
    "    X = data[:, 2:]\n",
    "    y_baseline = data[:, 1]\n",
    "    y = data[:, 0]\n",
    "    \n",
    "    \n",
    "    X = np.array([experiment - np.max(experiment) for experiment in X])\n",
    "    X = np.array([experiment/-np.min(experiment) for experiment in X])\n",
    "\n",
    "    y = np.round(y)\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    ## Let's shift each signal so that reference time matches for each signal\n",
    "    mean_ref_time = int(y.mean())\n",
    "    X = np.array([signal_cyclic_shift(signal, mean_ref_time - y[i]) for i, signal in enumerate(X, 0)])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def get_freq_data(X, freq=1, start_point=384):\n",
    "    X_freq = np.concatenate([X[:, start_point::-freq][:, ::-1], X[:, start_point + freq::freq]], axis=1)\n",
    "    return X_freq\n",
    "\n",
    "def signal_cyclic_shift(signal, tau):\n",
    "    signal_start = signal[:-tau]\n",
    "    \n",
    "    new_signal = np.concatenate([signal[-tau:], signal_start])\n",
    "    \n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_origin, y_origin = get_data()\n",
    "\n",
    "mean_argmin =  int(np.argmin(X_origin, axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_multi_signal(X_origin, tau, alpha, to_plot=False):\n",
    "    first_idx, second_idx = np.random.choice(X_origin.shape[0], 2, replace=False)\n",
    "    first_impulse = X_origin[first_idx]\n",
    "    second_impulse = X_origin[second_idx]\n",
    "    \n",
    "    \n",
    "    ### Randomly choose what signal to shift\n",
    "    if random.choice([True, False]):\n",
    "        first_impulse = signal_cyclic_shift(first_impulse, tau)\n",
    "    else:\n",
    "        second_impulse = signal_cyclic_shift(second_impulse, tau)\n",
    "    \n",
    "    \n",
    "    multi_impulse = first_impulse + second_impulse*alpha\n",
    "    multi_impulse /= -np.min(multi_impulse)\n",
    "    \n",
    "    first_impulse_shifted = signal_cyclic_shift(first_impulse, mean_argmin - np.argmin(first_impulse))\n",
    "    second_impulse_shifted = signal_cyclic_shift(second_impulse, mean_argmin - np.argmin(second_impulse))\n",
    "    multi_impulse_shifted = signal_cyclic_shift(multi_impulse, mean_argmin - np.argmin(multi_impulse))\n",
    "\n",
    "    if to_plot:\n",
    "        plt.plot(first_impulse_shifted)\n",
    "        plt.plot(second_impulse_shifted)\n",
    "        plt.plot(multi_impulse_shifted)\n",
    "        plt.legend(['First signal', 'Second signal', 'Sum of signals'])\n",
    "        plt.show()\n",
    "        \n",
    "    return {'first': first_impulse_shifted,\\\n",
    "            'second': second_impulse_shifted,\\\n",
    "            'multi': multi_impulse_shifted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_data(X_origin, tau_range, alpha_range, data_size=1000, to_print=False):    \n",
    "    X = []\n",
    "    y = []\n",
    "    alpha_values = []\n",
    "    tau_values = []\n",
    "    for i in range(data_size):\n",
    "        alpha = random.choice(alpha_range)\n",
    "        tau = random.choice(tau_range)\n",
    "        signal = generate_multi_signal(X_origin, tau, alpha)['multi']\n",
    "        \n",
    "        X.append(signal)\n",
    "        y.append(np.log10(alpha))\n",
    "        \n",
    "        alpha_values.append(alpha)\n",
    "        tau_values.append(tau)\n",
    "   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if to_print:\n",
    "        print(\"X shape:\", X.shape)\n",
    "        print(\"y shape:\", y.shape)\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "#     plt.scatter(alpha_values, tau_values)\n",
    "#     plt.show()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_range = np.array([np.around(10**i, decimals=4) for i in np.arange(0, 3.1, 0.01)])\n",
    "\n",
    "alpha_range = np.array([10**i for i in np.arange(0, 3, 0.05)])\n",
    "tau_range = np.arange(-100, 101, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (7848, 1024)\n",
      "y shape: (7848,)\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_data(X_origin, tau_range, alpha_range, data_size=len(X_origin), to_print=True)\n",
    "X = get_freq_data(X, freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Alpha distribution\")\n",
    "plt.hist(alpha_range)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Target distribution\")\n",
    "plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores():\n",
    "    for model in models:    \n",
    "        model_name = type(model).__name__\n",
    "        print(\"Regressor:\", model_name)\n",
    "    #         stregr = StackingRegressor(regressors=models, meta_regressor=model)\n",
    "        scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "        scores = cross_validate(model, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "        r2_score_mean = scores['test_r2'].mean()\n",
    "        r2_score_std = scores['test_r2'].std()\n",
    "        mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "        mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "        mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "        mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "        rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "        rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "        cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                          (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "        print(\"95% confidence interval:\")\n",
    "        for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "            print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "        print('----------------------------------')\n",
    "    print('____________________________________________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    huber_reg = HuberRegressor(epsilon= 4.927, alpha= 0.00759)\n",
    "    ridge_reg = linear_model.Ridge(solver='saga', max_iter=5000, alpha= 1)\n",
    "    lasso_reg = linear_model.Lasso(max_iter=5000, alpha=0.0001, normalize=False)\n",
    "    dt_reg = tree.DecisionTreeRegressor(min_samples_split=9, min_samples_leaf=6, min_weight_fraction_leaf=0.03, \n",
    "                                                                                                 max_features='auto')\n",
    "\n",
    "    pa_reg = PassiveAggressiveRegressor(C=0.00611, max_iter=2800, tol=5.719679731382862e-05)\n",
    "    xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", alpha= 0.01, booster='gbtree', eta= 0.323, gamma=0.189, \n",
    "                               reg_lambda=0.48, max_depth=6, verbosity=0)\n",
    "    return [huber_reg, ridge_reg, lasso_reg, dt_reg,  pa_reg, xgb_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor: HuberRegressor\n",
      "95% confidence interval:\n",
      "r2 score: 0.47703 (+/- 0.02199)\n",
      "mse score: 0.39155 (+/- 0.02744)\n",
      "mae score: 0.52426 (+/- 0.01391)\n",
      "rmse score: 0.62565 (+/- 0.02182)\n",
      "----------------------------------\n",
      "Regressor: Ridge\n",
      "95% confidence interval:\n",
      "r2 score: 0.48087 (+/- 0.01689)\n",
      "mse score: 0.38870 (+/- 0.02636)\n",
      "mae score: 0.52130 (+/- 0.01381)\n",
      "rmse score: 0.62337 (+/- 0.02106)\n",
      "----------------------------------\n",
      "Regressor: Lasso\n",
      "95% confidence interval:\n",
      "r2 score: 0.48684 (+/- 0.01677)\n",
      "mse score: 0.38423 (+/- 0.02646)\n",
      "mae score: 0.51876 (+/- 0.01419)\n",
      "rmse score: 0.61978 (+/- 0.02127)\n",
      "----------------------------------\n",
      "Regressor: DecisionTreeRegressor\n",
      "95% confidence interval:\n",
      "r2 score: 0.65451 (+/- 0.03170)\n",
      "mse score: 0.25876 (+/- 0.03119)\n",
      "mae score: 0.34817 (+/- 0.02150)\n",
      "rmse score: 0.50845 (+/- 0.03035)\n",
      "----------------------------------\n",
      "Regressor: PassiveAggressiveRegressor\n",
      "95% confidence interval:\n",
      "r2 score: 0.33299 (+/- 0.39150)\n",
      "mse score: 0.49804 (+/- 0.28083)\n",
      "mae score: 0.57965 (+/- 0.15649)\n",
      "rmse score: 0.69974 (+/- 0.18344)\n",
      "----------------------------------\n",
      "Regressor: XGBRegressor\n",
      "95% confidence interval:\n",
      "r2 score: 0.80149 (+/- 0.02074)\n",
      "mse score: 0.14874 (+/- 0.02154)\n",
      "mae score: 0.23783 (+/- 0.01431)\n",
      "rmse score: 0.38542 (+/- 0.02740)\n",
      "----------------------------------\n",
      "____________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaregressor: HuberRegressor\n",
      "95% confindence interval:\n",
      "r2 score: 0.81140 (+/- 0.01870)\n",
      "mse score: 0.14132 (+/- 0.02008)\n",
      "mae score: 0.23638 (+/- 0.01425)\n",
      "rmse score: 0.37570 (+/- 0.02619)\n",
      "--------------------------------------------------------\n",
      "Metaregressor: Ridge\n",
      "95% confindence interval:\n",
      "r2 score: 0.81141 (+/- 0.01877)\n",
      "mse score: 0.14132 (+/- 0.02014)\n",
      "mae score: 0.23654 (+/- 0.01436)\n",
      "rmse score: 0.37569 (+/- 0.02625)\n",
      "--------------------------------------------------------\n",
      "Metaregressor: Lasso\n",
      "95% confindence interval:\n",
      "r2 score: 0.81144 (+/- 0.01878)\n",
      "mse score: 0.14129 (+/- 0.02016)\n",
      "mae score: 0.23665 (+/- 0.01429)\n",
      "rmse score: 0.37566 (+/- 0.02628)\n",
      "--------------------------------------------------------\n",
      "Metaregressor: DecisionTreeRegressor\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d2405407fa3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_regressor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstregr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mr2_score_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_r2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 231\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mlxtend/regressor/stacking_regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    models = get_models()\n",
    "    print(\"Metaregressor:\", type(models[i]).__name__)\n",
    "\n",
    "    stregr = StackingRegressor(regressors=models, meta_regressor=models[i])\n",
    "    scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "    scores = cross_validate(stregr, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "    r2_score_mean = scores['test_r2'].mean()\n",
    "    r2_score_std = scores['test_r2'].std()\n",
    "    mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "    mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "    mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "    mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "    rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "    rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "    cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                      (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "    print(\"95% confindence interval:\")\n",
    "    for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "        print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_scores = []\n",
    "alpha_test_range = np.arange(1, 102, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingRegressor(meta_regressor=HuberRegressor(alpha=0.00759, epsilon=4.927,\n",
       "                                                fit_intercept=True,\n",
       "                                                max_iter=100, tol=1e-05,\n",
       "                                                warm_start=False),\n",
       "                  refit=True,\n",
       "                  regressors=[HuberRegressor(alpha=0.00759, epsilon=4.927,\n",
       "                                             fit_intercept=True, max_iter=100,\n",
       "                                             tol=1e-05, warm_start=False),\n",
       "                              Ridge(alpha=1, copy_X=True, fit_intercept=True,\n",
       "                                    max_iter=5000, normalize=False,\n",
       "                                    random_state=...\n",
       "                                           gamma=0.189, importance_type='gain',\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=6, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='reg:linear',\n",
       "                                           random_state=0, reg_alpha=0,\n",
       "                                           reg_lambda=0.48, scale_pos_weight=1,\n",
       "                                           seed=None, silent=None, subsample=1,\n",
       "                                           verbosity=0)],\n",
       "                  store_train_meta_features=False,\n",
       "                  use_features_in_secondary=False, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StackingRegressor(regressors=models, meta_regressor=models[0])\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alpha_test_range:\n",
    "    X_cur, y_cur = prepare_data(X_origin, tau_range, [alpha], data_size=1000, to_print=False)\n",
    "    y_pred = model.predict(X_cur)\n",
    "    alpha_scores.append(mean_absolute_error(y_pred, y_cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alpha_scores)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
