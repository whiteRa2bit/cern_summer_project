{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_model(path, model):\n",
    "    with open(path, 'wb') as fid:\n",
    "        pickle.dump(model, fid)  \n",
    "        \n",
    "def load_model(path):\n",
    "    with open(path, 'rb') as fid:\n",
    "        model = pickle.load(fid)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_values = [1, 5, 10, 15, 25, 50, 60, 75, 85, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = './models/classifier/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_kn(params_dict, freq):\n",
    "    kn_params[freq]['n_neighbors'] = int(params_dict['n_neighbors'])\n",
    "    kn_params[freq]['weights'] = ['uniform', 'distance'][params_dict['weights']]\n",
    "    kn_params[freq]['algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute'][params_dict['algorithm']]\n",
    "    kn_params[freq]['leaf_size'] = int(params_dict['leaf_size'])\n",
    "    kn_params[freq]['p'] = [1, 2][params_dict['p']]\n",
    "    \n",
    "kn_params = {freq:{'n_neighbors': None, 'weights': None, 'algorithm': None, 'leaf_size': None, 'p': None}\\\n",
    "                                                                                     for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'algorithm': 1, 'leaf_size': 50.0, 'n_neighbors': 6.0, 'p': 0, 'weights': 1}\n",
    "hyperopt_params[5] = {'algorithm': 0, 'leaf_size': 16.0, 'n_neighbors': 9.0, 'p': 1, 'weights': 1}\n",
    "hyperopt_params[10] = {'algorithm': 1, 'leaf_size': 36.0, 'n_neighbors': 4.0, 'p': 1, 'weights': 1}\n",
    "hyperopt_params[15] = {'algorithm': 0, 'leaf_size': 12.0, 'n_neighbors': 6.0, 'p': 0, 'weights': 1}\n",
    "hyperopt_params[25] = {'algorithm': 0, 'leaf_size': 4.0, 'n_neighbors': 2.0, 'p': 1, 'weights': 1}\n",
    "hyperopt_params[50] = {'algorithm': 2, 'leaf_size': 20.0, 'n_neighbors': 9.0, 'p': 0, 'weights': 1}\n",
    "hyperopt_params[60] = {'algorithm': 1, 'leaf_size': 16.0, 'n_neighbors': 10.0, 'p': 0, 'weights': 1}\n",
    "hyperopt_params[75] = {'algorithm': 2, 'leaf_size': 46.0, 'n_neighbors': 6.0, 'p': 1, 'weights': 1}\n",
    "hyperopt_params[85] = {'algorithm': 0, 'leaf_size': 24.0, 'n_neighbors': 9.0, 'p': 0, 'weights': 1}\n",
    "hyperopt_params[100] = {'algorithm': 3, 'leaf_size': 14.0, 'n_neighbors': 9.0, 'p': 0, 'weights': 1}\n",
    "\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_kn(hyperopt_params[freq], freq)\n",
    "    \n",
    "for freq in freq_values:\n",
    "    model = KNeighborsClassifier(n_neighbors=kn_params[freq]['n_neighbors'],\\\n",
    "                                 weights=kn_params[freq]['weights'], algorithm=kn_params[freq]['algorithm'],\\\n",
    "                                 leaf_size=kn_params[freq]['leaf_size'], p=kn_params[freq]['p'])\n",
    "    \n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_dt(params_dict, freq):\n",
    "    dt_params[freq]['max_depth'] = params_dict['max_depth']\n",
    "    dt_params[freq]['max_features'] = ['auto', 'sqrt', 'log2'][params_dict['max_features']]\n",
    "    dt_params[freq]['criterion'] = [\"gini\", \"entropy\"][params_dict['criterion']]\n",
    "    dt_params[freq]['min_samples_split'] = int(params_dict['min_samples_split'])\n",
    "    dt_params[freq]['min_samples_leaf'] = int(params_dict['min_samples_leaf'])\n",
    "    dt_params[freq]['min_weight_fraction_leaf'] = params_dict['min_weight_fraction_leaf']\n",
    "\n",
    "    \n",
    "dt_params = {freq:{'max_depth': None, 'max_features': None, 'criterion': None, 'min_samples_split': None,\\\n",
    "                   'min_samples_leaf': None, 'min_weight_fraction_leaf': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'criterion': 1, 'max_depth': 16, 'max_features': 1, 'min_samples_leaf': 3.0, 'min_samples_split': 10.0, 'min_weight_fraction_leaf': 0.0011012880111856103}\n",
    "hyperopt_params[5] = {'criterion': 0, 'max_depth': 13, 'max_features': 1, 'min_samples_leaf': 6.0, 'min_samples_split': 5.0, 'min_weight_fraction_leaf': 0.0007125292830519577}\n",
    "hyperopt_params[10] = {'criterion': 1, 'max_depth': 13, 'max_features': 0, 'min_samples_leaf': 4.0, 'min_samples_split': 8.0, 'min_weight_fraction_leaf': 0.0023420736375462502}\n",
    "hyperopt_params[15] = {'criterion': 1, 'max_depth': 18, 'max_features': 2, 'min_samples_leaf': 3.0, 'min_samples_split': 9.0, 'min_weight_fraction_leaf': 0.00029634263861464793}\n",
    "hyperopt_params[25] = {'criterion': 0, 'max_depth': 16, 'max_features': 1, 'min_samples_leaf': 10.0, 'min_samples_split': 10.0, 'min_weight_fraction_leaf': 0.001057073698162895}\n",
    "hyperopt_params[50] = {'criterion': 1, 'max_depth': 15, 'max_features': 0, 'min_samples_leaf': 2.0, 'min_samples_split': 8.0, 'min_weight_fraction_leaf': 0.008641651616123503}\n",
    "hyperopt_params[60] = {'criterion': 0, 'max_depth': 17, 'max_features': 1, 'min_samples_leaf': 2.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.0035923695507163547}\n",
    "hyperopt_params[75] = {'criterion': 0, 'max_depth': 9, 'max_features': 1, 'min_samples_leaf': 7.0, 'min_samples_split': 6.0, 'min_weight_fraction_leaf': 0.008486706928488966}\n",
    "hyperopt_params[85] = {'criterion': 0, 'max_depth': 14, 'max_features': 0, 'min_samples_leaf': 2.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.0008832297964638193}\n",
    "hyperopt_params[100] = {'criterion': 0, 'max_depth': 13, 'max_features': 2, 'min_samples_leaf': 5.0, 'min_samples_split': 3.0, 'min_weight_fraction_leaf': 0.002954853576859179}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_dt(hyperopt_params[freq], freq)\n",
    "    \n",
    "for freq in freq_values:\n",
    "    model = DecisionTreeClassifier(max_depth=dt_params[freq]['max_depth'], max_features=dt_params[freq]['max_features'],\\\n",
    "                                  criterion=dt_params[freq]['criterion'], min_samples_split=dt_params[freq]['min_samples_split'],\\\n",
    "                                  min_samples_leaf=dt_params[freq]['min_samples_leaf'], min_weight_fraction_leaf = dt_params[freq]['min_weight_fraction_leaf'])\n",
    "    \n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_rf(params_dict, freq):\n",
    "    rf_params[freq]['max_depth'] = params_dict['max_depth']\n",
    "    rf_params[freq]['max_features'] = ['auto', 'sqrt', 'log2'][params_dict['max_features']]\n",
    "    rf_params[freq]['criterion'] = [\"gini\", \"entropy\"][params_dict['criterion']]\n",
    "    rf_params[freq]['min_samples_split'] = int(params_dict['min_samples_split'])\n",
    "    rf_params[freq]['min_samples_leaf'] = int(params_dict['min_samples_leaf'])\n",
    "    rf_params[freq]['min_weight_fraction_leaf'] = params_dict['min_weight_fraction_leaf']\n",
    "\n",
    "    \n",
    "rf_params = {freq:{'max_depth': None, 'max_features': None, 'criterion': None, 'min_samples_split': None,\\\n",
    "                   'min_samples_leaf': None, 'min_weight_fraction_leaf': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'criterion': 1, 'max_depth': 16, 'max_features': 0, 'min_samples_leaf': 3.0, 'min_samples_split': 3.0, 'min_weight_fraction_leaf': 0.00200221370528991}\n",
    "hyperopt_params[5] = {'criterion': 1, 'max_depth': 15, 'max_features': 0, 'min_samples_leaf': 4.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.00046193264984031326}\n",
    "hyperopt_params[10] = {'criterion': 1, 'max_depth': 17, 'max_features': 2, 'min_samples_leaf': 8.0, 'min_samples_split': 6.0, 'min_weight_fraction_leaf': 0.002130761134581058}\n",
    "hyperopt_params[15] = {'criterion': 1, 'max_depth': 14, 'max_features': 2, 'min_samples_leaf': 1.0, 'min_samples_split': 8.0, 'min_weight_fraction_leaf': 0.005571102403480356}\n",
    "hyperopt_params[25] = {'criterion': 1, 'max_depth': 15, 'max_features': 0, 'min_samples_leaf': 3.0, 'min_samples_split': 3.0, 'min_weight_fraction_leaf': 0.00012641844592333357}\n",
    "hyperopt_params[50] = {'criterion': 0, 'max_depth': 17, 'max_features': 0, 'min_samples_leaf': 5.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.0036384794127141996}\n",
    "hyperopt_params[60] = {'criterion': 0, 'max_depth': 16, 'max_features': 1, 'min_samples_leaf': 4.0, 'min_samples_split': 5.0, 'min_weight_fraction_leaf': 0.00013589663154166091}\n",
    "hyperopt_params[75] = {'criterion': 0, 'max_depth': 17, 'max_features': 2, 'min_samples_leaf': 1.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 4.104677432711717e-05}\n",
    "hyperopt_params[85] = {'criterion': 1, 'max_depth': 13, 'max_features': 1, 'min_samples_leaf': 7.0, 'min_samples_split': 3.0, 'min_weight_fraction_leaf': 0.0003050496621625311}\n",
    "hyperopt_params[100] = {'criterion': 1, 'max_depth': 18, 'max_features': 0, 'min_samples_leaf': 8.0, 'min_samples_split': 8.0, 'min_weight_fraction_leaf': 7.886026864994738e-05}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_rf(hyperopt_params[freq], freq)\n",
    "    \n",
    "\n",
    "for freq in freq_values:\n",
    "    model = RandomForestClassifier(max_depth=rf_params[freq]['max_depth'], max_features=rf_params[freq]['max_features'],\\\n",
    "                                  criterion=rf_params[freq]['criterion'], min_samples_split=rf_params[freq]['min_samples_split'],\\\n",
    "                                  min_samples_leaf=rf_params[freq]['min_samples_leaf'], min_weight_fraction_leaf = rf_params[freq]['min_weight_fraction_leaf'],\\\n",
    "                                  verbose=0)\n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_nb(params_dict, freq):\n",
    "    nb_params[freq]['var_smoothing'] = params_dict['var_smoothing']\n",
    "    \n",
    "nb_params = {freq:{'var_smoothing': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'var_smoothing': 1.2460184378655685e-09}\n",
    "hyperopt_params[5] = {'var_smoothing': 1.0282014918470923e-10}\n",
    "hyperopt_params[10] = {'var_smoothing': 6.377556397965757e-10}\n",
    "hyperopt_params[15] = {'var_smoothing': 2.2962117400154974e-09}\n",
    "hyperopt_params[25] = {'var_smoothing': 1.2908377701761542e-08}\n",
    "hyperopt_params[50] = {'var_smoothing': 6.490487471670385e-09}\n",
    "hyperopt_params[60] = {'var_smoothing': 5.976912618238698e-09}\n",
    "hyperopt_params[75] = {'var_smoothing': 4.791540789108842e-10}\n",
    "hyperopt_params[85] = {'var_smoothing': 1.676267544339988e-10}\n",
    "hyperopt_params[100] = {'var_smoothing': 5.838586353515949e-09}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_nb(hyperopt_params[freq], freq)\n",
    "    \n",
    "\n",
    "for freq in freq_values:\n",
    "    model = GaussianNB(var_smoothing=nb_params[freq]['var_smoothing'])\n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_pa(params_dict, freq):\n",
    "    pa_params[freq]['C'] = params_dict['C']\n",
    "    pa_params[freq]['fit_intercept'] = [True, False][params_dict['fit_intercept']]\n",
    "\n",
    "    \n",
    "pa_params = {freq:{'C': None, 'fit_intercept': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'C': 0.024110225325426015, 'fit_intercept': 0}\n",
    "hyperopt_params[5] = {'C': 0.4973703807068094, 'fit_intercept': 1}\n",
    "hyperopt_params[10] = {'C': 0.13449519398904142, 'fit_intercept': 0}\n",
    "hyperopt_params[15] = {'C': 0.14875857076238322, 'fit_intercept': 0}\n",
    "hyperopt_params[25] = {'C': 0.2704430957411047, 'fit_intercept': 0}\n",
    "hyperopt_params[50] = {'C': 0.5089077894613963, 'fit_intercept': 0}\n",
    "hyperopt_params[60] = {'C': 0.7574288735094685, 'fit_intercept': 0}\n",
    "hyperopt_params[75] = {'C': 0.9283106465514318, 'fit_intercept': 1}\n",
    "hyperopt_params[85] = {'C': 0.8758158654804743, 'fit_intercept': 0}\n",
    "hyperopt_params[100] = {'C': 0.5022782066219091, 'fit_intercept': 1}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_pa(hyperopt_params[freq], freq)\n",
    "    \n",
    "\n",
    "for freq in freq_values:\n",
    "    model = PassiveAggressiveClassifier(C=pa_params[freq]['C'], fit_intercept=pa_params[freq]['fit_intercept'])\n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'space' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b8a72007d3ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     model = MLPClassifier(hidden_layer_sizes=(space['first_size'], space['second_size']), \n\u001b[0m\u001b[1;32m     27\u001b[0m                           \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                          max_iter=space['max_iter'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'space' is not defined"
     ]
    }
   ],
   "source": [
    "def process_hyperopt_params_mlp(params_dict, freq):\n",
    "    mlp_params[freq]['C'] = params_dict['C']\n",
    "    mlp_params[freq]['fit_intercept'] = [True, False][params_dict['fit_intercept']]\n",
    "\n",
    "    \n",
    "mlp_params = {freq:{'first_size': None, 'second_size': None, 'activation': None, 'max_iter': None,} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'C': 0.024110225325426015, 'fit_intercept': 0}\n",
    "hyperopt_params[5] = {'C': 0.4973703807068094, 'fit_intercept': 1}\n",
    "hyperopt_params[10] = {'C': 0.13449519398904142, 'fit_intercept': 0}\n",
    "hyperopt_params[15] = {'C': 0.14875857076238322, 'fit_intercept': 0}\n",
    "hyperopt_params[25] = {'C': 0.2704430957411047, 'fit_intercept': 0}\n",
    "hyperopt_params[50] = {'C': 0.5089077894613963, 'fit_intercept': 0}\n",
    "hyperopt_params[60] = {'C': 0.7574288735094685, 'fit_intercept': 0}\n",
    "hyperopt_params[75] = {'C': 0.9283106465514318, 'fit_intercept': 1}\n",
    "hyperopt_params[85] = {'C': 0.8758158654804743, 'fit_intercept': 0}\n",
    "hyperopt_params[100] = {'C': 0.5022782066219091, 'fit_intercept': 1}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_mlp(hyperopt_params[freq], freq)\n",
    "    \n",
    "\n",
    "for freq in freq_values:\n",
    "    model = MLPClassifier(hidden_layer_sizes=(space['first_size'], space['second_size']), \n",
    "                          activation=space['activation'], batch_size=16,\n",
    "                         max_iter=space['max_iter'])\n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference time regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = './models/reference_time_regressor/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_hb(params_dict, freq):\n",
    "    hb_params[freq]['epsilon'] = params_dict['epsilon']\n",
    "    hb_params[freq]['max_iter'] = params_dict['max_iter']\n",
    "    hb_params[freq]['alpha'] = params_dict['alpha']\n",
    "    \n",
    "hb_params = {freq:{'epsilon': None, 'max_iter': None, 'alpha': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'var_smoothing': 1.2460184378655685e-09}\n",
    "hyperopt_params[5] = {'var_smoothing': 1.0282014918470923e-10}\n",
    "hyperopt_params[10] = {'var_smoothing': 6.377556397965757e-10}\n",
    "hyperopt_params[15] = {'var_smoothing': 2.2962117400154974e-09}\n",
    "hyperopt_params[25] = {'var_smoothing': 1.2908377701761542e-08}\n",
    "hyperopt_params[50] = {'var_smoothing': 6.490487471670385e-09}\n",
    "hyperopt_params[60] = {'var_smoothing': 5.976912618238698e-09}\n",
    "hyperopt_params[75] = {'var_smoothing': 4.791540789108842e-10}\n",
    "hyperopt_params[85] = {'var_smoothing': 1.676267544339988e-10}\n",
    "hyperopt_params[100] = {'var_smoothing': 5.838586353515949e-09}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_hb(hyperopt_params[freq], freq)\n",
    "    \n",
    "\n",
    "for freq in freq_values:\n",
    "    model = HuberRegressor(epsilon=hb_params[freq]['epsilon'], max_iter=hb_params[freq]['max_iter'],\\\n",
    "                           alpha=hb_params[freq]['alpha'])\n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_ridge(params_dict, freq):\n",
    "    ridge_params[freq]['alpha'] = params_dict['alpha']\n",
    "    ridge_params[freq]['solver'] = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'][params_dict['solver']]\n",
    "    ridge_params[freq]['max_iter'] = params_dict['max_iter']\n",
    "    \n",
    "ridge_params = {freq:{'solver': None, 'max_iter': None, 'alpha': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'var_smoothing': 1.2460184378655685e-09}\n",
    "hyperopt_params[5] = {'var_smoothing': 1.0282014918470923e-10}\n",
    "hyperopt_params[10] = {'var_smoothing': 6.377556397965757e-10}\n",
    "hyperopt_params[15] = {'var_smoothing': 2.2962117400154974e-09}\n",
    "hyperopt_params[25] = {'var_smoothing': 1.2908377701761542e-08}\n",
    "hyperopt_params[50] = {'var_smoothing': 6.490487471670385e-09}\n",
    "hyperopt_params[60] = {'var_smoothing': 5.976912618238698e-09}\n",
    "hyperopt_params[75] = {'var_smoothing': 4.791540789108842e-10}\n",
    "hyperopt_params[85] = {'var_smoothing': 1.676267544339988e-10}\n",
    "hyperopt_params[100] = {'var_smoothing': 5.838586353515949e-09}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_ridge(hyperopt_params[freq], freq)\n",
    "    \n",
    "\n",
    "for freq in freq_values:\n",
    "    model = linear_model.Ridge(solver=ridge_params[freq]['solver'], max_iter=ridge_params[freq]['max_iter'],\\\n",
    "                                alpha=ridge_params[freq]['alpha'])\n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_lasso(params_dict, freq):\n",
    "    lasso_params[freq]['alpha'] = params_dict['alpha']\n",
    "    lasso_params[freq]['normalize'] = [True, False][params_dict['normalize']]\n",
    "    lasso_params[freq]['max_iter'] = params_dict['max_iter']\n",
    "    \n",
    "lasso_params = {freq:{'normalize': None, 'max_iter': None, 'alpha': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'var_smoothing': 1.2460184378655685e-09}\n",
    "hyperopt_params[5] = {'var_smoothing': 1.0282014918470923e-10}\n",
    "hyperopt_params[10] = {'var_smoothing': 6.377556397965757e-10}\n",
    "hyperopt_params[15] = {'var_smoothing': 2.2962117400154974e-09}\n",
    "hyperopt_params[25] = {'var_smoothing': 1.2908377701761542e-08}\n",
    "hyperopt_params[50] = {'var_smoothing': 6.490487471670385e-09}\n",
    "hyperopt_params[60] = {'var_smoothing': 5.976912618238698e-09}\n",
    "hyperopt_params[75] = {'var_smoothing': 4.791540789108842e-10}\n",
    "hyperopt_params[85] = {'var_smoothing': 1.676267544339988e-10}\n",
    "hyperopt_params[100] = {'var_smoothing': 5.838586353515949e-09}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_lasso(hyperopt_params[freq], freq)\n",
    "    \n",
    "\n",
    "for freq in freq_values:\n",
    "    model = linear_model.Lasso(max_iter=lasso_params[freq]['max_iter'], alpha=lasso_params[freq]['alpha'],\\\n",
    "                               normalize=lasso_params[freq]['normalize'])\n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_dt(params_dict, freq):\n",
    "    dt_params[freq]['max_depth'] = params_dict['max_depth']\n",
    "    dt_params[freq]['max_features'] = ['auto', 'sqrt', 'log2'][params_dict['max_features']]\n",
    "    dt_params[freq]['min_samples_split'] = int(params_dict['min_samples_split'])\n",
    "    dt_params[freq]['min_samples_leaf'] = int(params_dict['min_samples_leaf'])\n",
    "    dt_params[freq]['min_weight_fraction_leaf'] = params_dict['min_weight_fraction_leaf']\n",
    "\n",
    "    \n",
    "dt_params = {freq:{'max_depth': None, 'max_features': None, 'min_samples_split': None,\\\n",
    "                   'min_samples_leaf': None, 'min_weight_fraction_leaf': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'criterion': 1, 'max_depth': 16, 'max_features': 1, 'min_samples_leaf': 3.0, 'min_samples_split': 10.0, 'min_weight_fraction_leaf': 0.0011012880111856103}\n",
    "hyperopt_params[5] = {'criterion': 0, 'max_depth': 13, 'max_features': 1, 'min_samples_leaf': 6.0, 'min_samples_split': 5.0, 'min_weight_fraction_leaf': 0.0007125292830519577}\n",
    "hyperopt_params[10] = {'criterion': 1, 'max_depth': 13, 'max_features': 0, 'min_samples_leaf': 4.0, 'min_samples_split': 8.0, 'min_weight_fraction_leaf': 0.0023420736375462502}\n",
    "hyperopt_params[15] = {'criterion': 1, 'max_depth': 18, 'max_features': 2, 'min_samples_leaf': 3.0, 'min_samples_split': 9.0, 'min_weight_fraction_leaf': 0.00029634263861464793}\n",
    "hyperopt_params[25] = {'criterion': 0, 'max_depth': 16, 'max_features': 1, 'min_samples_leaf': 10.0, 'min_samples_split': 10.0, 'min_weight_fraction_leaf': 0.001057073698162895}\n",
    "hyperopt_params[50] = {'criterion': 1, 'max_depth': 15, 'max_features': 0, 'min_samples_leaf': 2.0, 'min_samples_split': 8.0, 'min_weight_fraction_leaf': 0.008641651616123503}\n",
    "hyperopt_params[60] = {'criterion': 0, 'max_depth': 17, 'max_features': 1, 'min_samples_leaf': 2.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.0035923695507163547}\n",
    "hyperopt_params[75] = {'criterion': 0, 'max_depth': 9, 'max_features': 1, 'min_samples_leaf': 7.0, 'min_samples_split': 6.0, 'min_weight_fraction_leaf': 0.008486706928488966}\n",
    "hyperopt_params[85] = {'criterion': 0, 'max_depth': 14, 'max_features': 0, 'min_samples_leaf': 2.0, 'min_samples_split': 7.0, 'min_weight_fraction_leaf': 0.0008832297964638193}\n",
    "hyperopt_params[100] = {'criterion': 0, 'max_depth': 13, 'max_features': 2, 'min_samples_leaf': 5.0, 'min_samples_split': 3.0, 'min_weight_fraction_leaf': 0.002954853576859179}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_dt(hyperopt_params[freq], freq)\n",
    "    \n",
    "for freq in freq_values:\n",
    "    model =  tree.DecisionTreeRegressor(max_depth=dt_params[freq]['max_depth'], max_features=dt_params[freq]['max_features'],\\\n",
    "                                  criterion=dt_params[freq]['criterion'], min_samples_split=dt_params[freq]['min_samples_split'],\\\n",
    "                                  min_samples_leaf=dt_params[freq]['min_samples_leaf'], min_weight_fraction_leaf = dt_params[freq]['min_weight_fraction_leaf'])\n",
    "    \n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Passive Aggresive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_pa(params_dict, freq):\n",
    "    pa_params[freq]['tol'] = params_dict['tol']\n",
    "    pa_params[freq]['C'] = params_dict['C']\n",
    "    pa_params[freq]['max_iter'] = params_dict['max_iter']\n",
    "    \n",
    "pa_params = {freq:{'tol': None, 'max_iter': None, 'C': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'var_smoothing': 1.2460184378655685e-09}\n",
    "hyperopt_params[5] = {'var_smoothing': 1.0282014918470923e-10}\n",
    "hyperopt_params[10] = {'var_smoothing': 6.377556397965757e-10}\n",
    "hyperopt_params[15] = {'var_smoothing': 2.2962117400154974e-09}\n",
    "hyperopt_params[25] = {'var_smoothing': 1.2908377701761542e-08}\n",
    "hyperopt_params[50] = {'var_smoothing': 6.490487471670385e-09}\n",
    "hyperopt_params[60] = {'var_smoothing': 5.976912618238698e-09}\n",
    "hyperopt_params[75] = {'var_smoothing': 4.791540789108842e-10}\n",
    "hyperopt_params[85] = {'var_smoothing': 1.676267544339988e-10}\n",
    "hyperopt_params[100] = {'var_smoothing': 5.838586353515949e-09}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_pa(hyperopt_params[freq], freq)\n",
    "    \n",
    "\n",
    "for freq in freq_values:\n",
    "    model = PassiveAggressiveRegressor(max_iter=pa_params[freq]['max_iter'], tol=pa_params[freq]['tol'], \n",
    "                                       C = pa_params[freq]['C'])\n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hyperopt_params_ridge(params_dict, freq):\n",
    "    ridge_params[freq]['alpha'] = params_dict['alpha']\n",
    "    ridge_params[freq]['solver'] = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'][params_dict['solver']]\n",
    "    ridge_params[freq]['max_iter'] = params_dict['max_iter']\n",
    "    \n",
    "ridge_params = {freq:{'epsilon': None, 'max_iter': None, 'alpha': None} for freq in freq_values}\n",
    "\n",
    "hyperopt_params = {freq:None for freq in freq_values}\n",
    "\n",
    "hyperopt_params[1] = {'var_smoothing': 1.2460184378655685e-09}\n",
    "hyperopt_params[5] = {'var_smoothing': 1.0282014918470923e-10}\n",
    "hyperopt_params[10] = {'var_smoothing': 6.377556397965757e-10}\n",
    "hyperopt_params[15] = {'var_smoothing': 2.2962117400154974e-09}\n",
    "hyperopt_params[25] = {'var_smoothing': 1.2908377701761542e-08}\n",
    "hyperopt_params[50] = {'var_smoothing': 6.490487471670385e-09}\n",
    "hyperopt_params[60] = {'var_smoothing': 5.976912618238698e-09}\n",
    "hyperopt_params[75] = {'var_smoothing': 4.791540789108842e-10}\n",
    "hyperopt_params[85] = {'var_smoothing': 1.676267544339988e-10}\n",
    "hyperopt_params[100] = {'var_smoothing': 5.838586353515949e-09}\n",
    "\n",
    "for freq in freq_values:\n",
    "    process_hyperopt_params_ridge(hyperopt_params[freq], freq)\n",
    "    \n",
    "\n",
    "for freq in freq_values:\n",
    "    model = linear_model.Ridge(solver=ridge_params[freq]['solver'], max_iter=ridge_params[freq]['max_iter'],\\\n",
    "                                alpha=ridge_params[freq]['alpha'])\n",
    "    save_model(MODEL_SAVE_PATH + type(model).__name__ + '_freq_' + str(freq) + '.pkl', model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
