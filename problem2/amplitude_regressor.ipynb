{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    file = open('./data/shashlik_61_pulses.txt', 'r')\n",
    "    data = file.readlines()\n",
    "    data = np.array([list(map(float, experiment.split())) for experiment in data])\n",
    "   \n",
    "    X = data[:, 2:]\n",
    "    y_baseline = data[:, 1]\n",
    "    y = data[:, 0]\n",
    "    \n",
    "    \n",
    "    X = np.array([experiment - np.max(experiment) for experiment in X])\n",
    "    X = np.array([experiment/-np.min(experiment) for experiment in X])\n",
    "\n",
    "    y = np.round(y)\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    ## Let's shift each signal so that reference time matches for each signal\n",
    "    mean_ref_time = int(y.mean())\n",
    "    X = np.array([signal_cyclic_shift(signal, mean_ref_time - y[i]) for i, signal in enumerate(X, 0)])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def get_freq_data(X, freq=1, start_point=384):\n",
    "    X_freq = np.concatenate([X[:, start_point::-freq][:, ::-1], X[:, start_point + freq::freq]], axis=1)\n",
    "    return X_freq\n",
    "\n",
    "def signal_cyclic_shift(signal, tau):\n",
    "    signal_start = signal[:-tau]\n",
    "    \n",
    "    new_signal = np.concatenate([signal[-tau:], signal_start])\n",
    "    \n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_origin, y_origin = get_data()\n",
    "\n",
    "mean_argmin =  int(np.argmin(X_origin, axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_multi_signal(X_origin, tau, alpha, to_plot=False):\n",
    "    first_idx, second_idx = np.random.choice(X_origin.shape[0], 2, replace=False)\n",
    "    first_impulse = X_origin[first_idx]\n",
    "    second_impulse = X_origin[second_idx]\n",
    "    \n",
    "    \n",
    "    ### Randomly choose what signal to shift\n",
    "    if random.choice([True, False]):\n",
    "        first_impulse = signal_cyclic_shift(first_impulse, tau)\n",
    "    else:\n",
    "        second_impulse = signal_cyclic_shift(second_impulse, tau)\n",
    "    \n",
    "    \n",
    "    multi_impulse = first_impulse + second_impulse*alpha\n",
    "    multi_impulse /= -np.min(multi_impulse)\n",
    "    \n",
    "    first_impulse_shifted = signal_cyclic_shift(first_impulse, mean_argmin - np.argmin(first_impulse))\n",
    "    second_impulse_shifted = signal_cyclic_shift(second_impulse, mean_argmin - np.argmin(second_impulse))\n",
    "    multi_impulse_shifted = signal_cyclic_shift(multi_impulse, mean_argmin - np.argmin(multi_impulse))\n",
    "\n",
    "    if to_plot:\n",
    "        plt.plot(first_impulse_shifted)\n",
    "        plt.plot(second_impulse_shifted)\n",
    "        plt.plot(multi_impulse_shifted)\n",
    "        plt.legend(['First signal', 'Second signal', 'Sum of signals'])\n",
    "        plt.show()\n",
    "        \n",
    "    return {'first': first_impulse_shifted,\\\n",
    "            'second': second_impulse_shifted,\\\n",
    "            'multi': multi_impulse_shifted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_data(X_origin, tau_range, alpha_range, data_size=1000, to_print=False):    \n",
    "    X = []\n",
    "    y = []\n",
    "    alpha_values = []\n",
    "    tau_values = []\n",
    "    for i in range(data_size):\n",
    "        alpha = random.choice(alpha_range)\n",
    "        tau = random.choice(tau_range)\n",
    "        signal = generate_multi_signal(X_origin, tau, alpha)['multi']\n",
    "        \n",
    "        X.append(signal)\n",
    "        y.append(alpha)\n",
    "        \n",
    "        alpha_values.append(alpha)\n",
    "        tau_values.append(tau)\n",
    "   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if to_print:\n",
    "        print(\"X shape:\", X.shape)\n",
    "        print(\"y shape:\", y.shape)\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "#     plt.scatter(alpha_values, tau_values)\n",
    "#     plt.show()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_range = np.array([np.around(10**i, decimals=4) for i in np.arange(0, 3.1, 0.01)])\n",
    "\n",
    "alpha_range = np.arange(1, 100, 0.1)\n",
    "tau_range = np.arange(-100, 101, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5000, 1024)\n",
      "y shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_data(X_origin, tau_range, alpha_range, data_size=5000, to_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([485., 493., 485., 484., 529., 482., 521., 505., 488., 528.]),\n",
       " array([ 1.  , 10.89, 20.78, 30.67, 40.56, 50.45, 60.34, 70.23, 80.12,\n",
       "        90.01, 99.9 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores():\n",
    "    for model in models:    \n",
    "        model_name = type(model).__name__\n",
    "        print(\"Regressor:\", model_name)\n",
    "    #         stregr = StackingRegressor(regressors=models, meta_regressor=model)\n",
    "        scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "        scores = cross_validate(model, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "        r2_score_mean = scores['test_r2'].mean()\n",
    "        r2_score_std = scores['test_r2'].std()\n",
    "        mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "        mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "        mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "        mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "        rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "        rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "        cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                          (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "        print(\"95% confidence interval:\")\n",
    "        for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "            print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "        print('----------------------------------')\n",
    "    print('____________________________________________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    huber_reg = HuberRegressor(epsilon= 4.927, alpha= 0.00759)\n",
    "    ridge_reg = linear_model.Ridge(solver='saga', max_iter=5000, alpha= 1)\n",
    "    lasso_reg = linear_model.Lasso(max_iter=4400, alpha=0.69, normalize=False)\n",
    "    dt_reg = tree.DecisionTreeRegressor(min_samples_split=7, min_samples_leaf=9, min_weight_fraction_leaf=0.1, \n",
    "                                                                                                 max_features='sqrt')\n",
    "\n",
    "    pa_reg = PassiveAggressiveRegressor(C=0.44, max_iter=2800, tol=2.4e-5)\n",
    "    xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", alpha= 0.01, booster='gbtree', eta= 0.323, gamma=0.189, \n",
    "                               reg_lambda=0.48, max_depth=6, verbosity=0)\n",
    "    return [huber_reg, ridge_reg, lasso_reg, dt_reg,  pa_reg, xgb_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaregressor: HuberRegressor\n",
      "95% confindence interval:\n",
      "r2 score: 0.22123 (+/- 0.03594)\n",
      "mse score: 633.15624 (+/- 10.51974)\n",
      "mae score: 21.53511 (+/- 0.39419)\n",
      "rmse score: 25.16238 (+/- 0.20919)\n",
      "----------------------------------\n",
      "Metaregressor: Ridge\n",
      "95% confindence interval:\n",
      "r2 score: 0.22358 (+/- 0.03766)\n",
      "mse score: 631.24110 (+/- 13.12181)\n",
      "mae score: 21.54483 (+/- 0.38615)\n",
      "rmse score: 25.12417 (+/- 0.26129)\n",
      "----------------------------------\n",
      "Metaregressor: Lasso\n",
      "95% confindence interval:\n",
      "r2 score: -0.00147 (+/- 0.00159)\n",
      "mse score: 814.53176 (+/- 28.78358)\n",
      "mae score: 24.69234 (+/- 0.68149)\n",
      "rmse score: 28.53888 (+/- 0.50522)\n",
      "----------------------------------\n",
      "Metaregressor: DecisionTreeRegressor\n",
      "95% confindence interval:\n",
      "r2 score: 0.35126 (+/- 0.09183)\n",
      "mse score: 527.08882 (+/- 59.59137)\n",
      "mae score: 18.71586 (+/- 0.99935)\n",
      "rmse score: 22.94940 (+/- 1.28639)\n",
      "----------------------------------\n",
      "Metaregressor: PassiveAggressiveRegressor\n",
      "95% confindence interval:\n",
      "r2 score: -0.65503 (+/- 1.44482)\n",
      "mse score: 1348.99715 (+/- 1193.60863)\n",
      "mae score: 29.58517 (+/- 14.34160)\n",
      "rmse score: 35.72722 (+/- 17.03679)\n",
      "----------------------------------\n",
      "Metaregressor: XGBRegressor\n",
      "95% confindence interval:\n",
      "r2 score: 0.67797 (+/- 0.04110)\n",
      "mse score: 261.73189 (+/- 28.84511)\n",
      "mae score: 11.48394 (+/- 0.73438)\n",
      "rmse score: 16.17196 (+/- 0.89351)\n",
      "----------------------------------\n",
      "____________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaregressor: HuberRegressor\n",
      "95% confindence interval:\n",
      "r2 score: 0.67866 (+/- 0.05126)\n",
      "mse score: 261.14823 (+/- 37.58071)\n",
      "mae score: 11.74306 (+/- 0.92921)\n",
      "rmse score: 16.14958 (+/- 1.16486)\n",
      "--------------------------------------------------------\n",
      "Metaregressor: Ridge\n",
      "95% confindence interval:\n",
      "r2 score: 0.67960 (+/- 0.04281)\n",
      "mse score: 260.43596 (+/- 31.27388)\n",
      "mae score: 11.73019 (+/- 0.77468)\n",
      "rmse score: 16.13079 (+/- 0.96644)\n",
      "--------------------------------------------------------\n",
      "Metaregressor: Lasso\n",
      "95% confindence interval:\n",
      "r2 score: 0.67878 (+/- 0.04385)\n",
      "mse score: 261.06808 (+/- 30.97335)\n",
      "mae score: 11.69821 (+/- 0.74832)\n",
      "rmse score: 16.15045 (+/- 0.96166)\n",
      "--------------------------------------------------------\n",
      "Metaregressor: DecisionTreeRegressor\n",
      "95% confindence interval:\n",
      "r2 score: 0.53648 (+/- 0.20509)\n",
      "mse score: 376.14502 (+/- 157.77536)\n",
      "mae score: 14.69575 (+/- 3.74448)\n",
      "rmse score: 19.28938 (+/- 4.03238)\n",
      "--------------------------------------------------------\n",
      "Metaregressor: PassiveAggressiveRegressor\n",
      "95% confindence interval:\n",
      "r2 score: 0.64927 (+/- 0.07020)\n",
      "mse score: 285.41490 (+/- 61.69265)\n",
      "mae score: 12.32058 (+/- 1.79469)\n",
      "rmse score: 16.86986 (+/- 1.81409)\n",
      "--------------------------------------------------------\n",
      "Metaregressor: XGBRegressor\n",
      "95% confindence interval:\n",
      "r2 score: 0.70062 (+/- 0.04446)\n",
      "mse score: 243.29572 (+/- 31.68544)\n",
      "mae score: 10.67017 (+/- 0.91767)\n",
      "rmse score: 15.58961 (+/- 1.01960)\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    models = get_models()\n",
    "    print(\"Metaregressor:\", type(models[i]).__name__)\n",
    "\n",
    "    stregr = StackingRegressor(regressors=models, meta_regressor=models[i])\n",
    "    scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "    scores = cross_validate(stregr, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "    r2_score_mean = scores['test_r2'].mean()\n",
    "    r2_score_std = scores['test_r2'].std()\n",
    "    mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "    mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "    mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "    mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "    rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "    rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "    cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                      (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "    print(\"95% confindence interval:\")\n",
    "    for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "        print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "    print('--------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
