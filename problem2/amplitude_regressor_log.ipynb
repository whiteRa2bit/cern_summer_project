{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_data, get_freq_data, signal_cyclic_shift, generate_multi_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_origin, y_origin = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_data(X_origin, y_origin, tau_range, alpha_range, data_size=1000, to_print=False):    \n",
    "    X = []\n",
    "    y = []\n",
    "    alpha_values = []\n",
    "    tau_values = []\n",
    "    for i in range(data_size):\n",
    "        alpha = random.choice(alpha_range)\n",
    "        tau = random.choice(tau_range)\n",
    "        signal = generate_multi_signal(X_origin, y_origin, tau, alpha)['multi_impulse']\n",
    "        \n",
    "        X.append(signal)\n",
    "        y.append(np.log10(alpha))\n",
    "        \n",
    "        alpha_values.append(alpha)\n",
    "        tau_values.append(tau)\n",
    "   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if to_print:\n",
    "        print(\"X shape:\", X.shape)\n",
    "        print(\"y shape:\", y.shape)\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "#     plt.scatter(alpha_values, tau_values)\n",
    "#     plt.show()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_range = np.array([np.around(10**i, decimals=4) for i in np.arange(0, 3.1, 0.01)])\n",
    "\n",
    "alpha_range = np.array([10**i for i in np.arange(0, 3, 0.05)])\n",
    "tau_range = np.arange(-100, 101, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (7848, 1024)\n",
      "y shape: (7848,)\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_data(X_origin, y_origin, tau_range, alpha_range, data_size=len(X_origin), to_print=True)\n",
    "X = get_freq_data(X, freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Alpha distribution\")\n",
    "plt.hist(alpha_range)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Target distribution\")\n",
    "plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores():\n",
    "    for model in models:    \n",
    "        model_name = type(model).__name__\n",
    "        print(\"Regressor:\", model_name)\n",
    "    #         stregr = StackingRegressor(regressors=models, meta_regressor=model)\n",
    "        scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "        scores = cross_validate(model, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "        r2_score_mean = scores['test_r2'].mean()\n",
    "        r2_score_std = scores['test_r2'].std()\n",
    "        mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "        mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "        mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "        mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "        rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "        rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "        cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                          (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "        print(\"95% confidence interval:\")\n",
    "        for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "            print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "        print('----------------------------------')\n",
    "    print('____________________________________________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    huber_reg = HuberRegressor(epsilon= 4.927, alpha= 0.00759)\n",
    "    ridge_reg = linear_model.Ridge(solver='saga', max_iter=5000, alpha= 1)\n",
    "    lasso_reg = linear_model.Lasso(max_iter=5000, alpha=0.0001, normalize=False)\n",
    "    dt_reg = tree.DecisionTreeRegressor(min_samples_split=9, min_samples_leaf=6, min_weight_fraction_leaf=0.03, \n",
    "                                                                                                 max_features='auto')\n",
    "\n",
    "    pa_reg = PassiveAggressiveRegressor(C=0.00611, max_iter=2800, tol=5.719679731382862e-05)\n",
    "    xgb_reg = xgb.XGBRegressor(objective=\"reg:linear\", alpha= 0.01, booster='gbtree', eta= 0.323, gamma=0.189, \n",
    "                               reg_lambda=0.48, max_depth=6, verbosity=0)\n",
    "    return [huber_reg, ridge_reg, lasso_reg, dt_reg,  pa_reg, xgb_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    models = get_models()\n",
    "    print(\"Metaregressor:\", type(models[i]).__name__)\n",
    "\n",
    "    stregr = StackingRegressor(regressors=models, meta_regressor=models[i])\n",
    "    scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "    scores = cross_validate(stregr, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "    r2_score_mean = scores['test_r2'].mean()\n",
    "    r2_score_std = scores['test_r2'].std()\n",
    "    mse_score_mean = -scores['test_neg_mean_squared_error'].mean()\n",
    "    mse_score_std = scores['test_neg_mean_squared_error'].std()\n",
    "    mae_score_mean = -scores['test_neg_mean_absolute_error'].mean()\n",
    "    mae_score_std = scores['test_neg_mean_absolute_error'].std()\n",
    "    rmse_score_mean = np.sqrt(-scores['test_neg_mean_squared_error']).mean()\n",
    "    rmse_score_std = np.sqrt(-scores['test_neg_mean_squared_error']).std()\n",
    "\n",
    "    cur_scores = [(r2_score_mean, r2_score_std), (mse_score_mean, mse_score_std),\\\n",
    "                      (mae_score_mean, mae_score_std), (rmse_score_mean, rmse_score_std)]\n",
    "    #         print('!!!!!!!!')\n",
    "    #         print(\"TEST\")\n",
    "    #         print(models_scores[type(models[0]).__name__]['r2'])\n",
    "    #         print('!!!!!!!!')\n",
    "    print(\"95% confindence interval:\")\n",
    "    for i, metric in enumerate(['r2', 'mse', 'mae', 'rmse'], 0):\n",
    "    #         models_scores[model_name][metric].append(cur_scores[i])\n",
    "        print(metric, \"score: %0.5f (+/- %0.5f)\" % (cur_scores[i][0], 2*cur_scores[i][1]))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot scores for different sampling frequency values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.array([np.around(10**i, decimals=4) for i in np.arange(0, 3.1, 0.1)])\n",
    "tau_values = range(-25, 30, 5)\n",
    "freq_values = [1, 25, 50, 60, 75, 85, 100]\n",
    "# alpha_values = np.around(np.arange(0, 100, 2), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(X_origin, alpha_values, tau_values, data_size=100, freq=1):\n",
    "    scores_dict = {}\n",
    "    \n",
    "    X, y = prepare_data(X_origin, tau_values, alpha_values, to_print=False, data_size=len(X_origin))\n",
    "    model = get_models()[-1]\n",
    "    X_freq = get_freq_data(X, freq=freq)\n",
    "    model.fit(X_freq, y)\n",
    "\n",
    "    \n",
    "    for tau in tqdm.tqdm(tau_values):\n",
    "        scores_dict[tau] = dict(zip(alpha_values, np.zeros(len(alpha_values))))\n",
    "        for alpha in alpha_values:\n",
    "            X_cur, y_cur = prepare_data(X_origin, [tau], [alpha], data_size=data_size)\n",
    "            X_cur = get_freq_data(X_cur, freq=freq)\n",
    "            \n",
    "            y_pred = model.predict(X_cur)\n",
    "            scores_dict[tau][alpha] = np.sqrt(mean_squared_error(y_pred, y_cur))\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_arrays(scores_dict):\n",
    "    x, y, z = [], [], []\n",
    "    for tau, alpha_dict in scores_dict.items():\n",
    "        for alpha, score in alpha_dict.items():\n",
    "            x.append(tau)\n",
    "            y.append(alpha)\n",
    "            z.append(score)\n",
    "            \n",
    "    return [x, y, z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "# matplotlib.use('Qt4Agg')\n",
    "\n",
    "def plot_score_3d(scores_dict):\n",
    "    x, y, z = dict_to_arrays(scores_dict)\n",
    "    alpha_values = list(scores_dict[list(scores_dict.keys())[0]].keys())\n",
    "    \n",
    "    fig1 = matplotlib.pyplot.figure(figsize=(7, 5))\n",
    "    ax1 = Axes3D(fig1)\n",
    "\n",
    "    ax1.set_yticks(np.log10(alpha_values[::10]))\n",
    "    ax1.set_yticklabels(alpha_values[::10])\n",
    "\n",
    "    ax1.set_xlabel(r\"${\\tau}$\", fontsize=15)\n",
    "    ax1.set_ylabel(r\"${\\alpha}$\", fontsize=15)\n",
    "    ax1.set_zlabel('Accuracy', fontsize=15)\n",
    "\n",
    "#     ax1.view_init(30, 150)\n",
    "    ax1.plot(10*x, np.log10(10*y), 10*z, 'ro', color='b', linewidth=3)\n",
    "\n",
    "    for angle in range(0, 180):\n",
    "        ax1.view_init(30, angle)\n",
    "        plt.draw()\n",
    "        plt.pause(.001)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "VMIN = 0\n",
    "VMAX = 1.6\n",
    "STEP = 0.2\n",
    "ORIGIN_FREQ = 5000\n",
    "\n",
    "def plot_color_map(scores_dict, alpha_values, tau_values, alpha_freq=10, tau_freq=2, freq=1):\n",
    "    _, _, z = dict_to_arrays(scores_dict)\n",
    "    z = np.array(z)\n",
    "    Z = z.reshape((len(tau_values), len(alpha_values)))\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    plt.title(\"RMSE log(alpha), frequency = \" + str(int(ORIGIN_FREQ/freq)) + ' [MHZ]')\n",
    "    plt.xlabel(\"Two signals ratio\", fontsize=12)\n",
    "    plt.ylabel(\"Delta t [ns]\", fontsize=12)\n",
    "    plt.xticks([alpha_freq*i for i in range(len(alpha_values[::alpha_freq]))], alpha_values[::alpha_freq])\n",
    "    plt.yticks([tau_freq*i for i in range(len(tau_values[::tau_freq]))], [0.2*el for el in tau_values[::tau_freq]])\n",
    "\n",
    "#     im = ax.imshow(Z, interpolation='bilinear', cmap='spring', aspect='auto')\n",
    "    im = ax.imshow(Z, interpolation='bilinear', cmap='spring', aspect='auto', vmin=VMIN, vmax=VMAX)\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.5)\n",
    "\n",
    "#     plt.colorbar(im, cax=cax)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_ticks(np.arange(VMIN, VMAX, STEP))\n",
    "    cbar.set_ticklabels(np.round(np.arange(VMIN, VMAX, STEP), decimals=1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('./data/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('./data/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for freq in freq_values:\n",
    "    X_origin, y_origin = get_data()\n",
    "    scores_dict = calculate_scores(X_origin, alpha_values, tau_values, data_size=1000, freq=freq)\n",
    "    plot_color_map(scores_dict, alpha_values, tau_values, freq=freq)\n",
    "    save_obj(scores_dict, 'scores_freq=' + str(freq))\n",
    "#     plot_score_3d(scores_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_models()[0]\n",
    "X_origin, y_origin = get_data()\n",
    "X, y = prepare_data(X_origin, tau_range, alpha_range, data_size=len(X_origin), to_print=True)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_data(X_origin, tau_range, alpha_range, data_size=1000, to_print=False):    \n",
    "    X = []\n",
    "    y = []\n",
    "    alpha_values = []\n",
    "    tau_values = []\n",
    "    for i in range(data_size):\n",
    "        alpha = random.choice(alpha_range)\n",
    "        tau = random.choice(tau_range)\n",
    "        signal = generate_multi_signal(X_origin, tau, alpha)['multi']\n",
    "        \n",
    "        X.append(signal)\n",
    "        y.append(np.log10(alpha))\n",
    "        \n",
    "        alpha_values.append(alpha)\n",
    "        tau_values.append(tau)\n",
    "   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if to_print:\n",
    "        print(\"X shape:\", X.shape)\n",
    "        print(\"y shape:\", y.shape)\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "#     plt.scatter(alpha_values, tau_values)\n",
    "#     plt.show()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cur, y_cur = prepare_data(X_origin, [100], [0.5], data_size=100)\n",
    "y_pred = model.predict(X_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_cur[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_pred, y_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_cur' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3183fc9d77b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_cur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_cur' is not defined"
     ]
    }
   ],
   "source": [
    "y_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(alpha_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = StackingRegressor(regressors=models, meta_regressor=models[0])\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_scores = []\n",
    "alpha_test_range = np.arange(1, 1002, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alpha_test_range:\n",
    "    X_cur, y_cur = prepare_data(X_origin, tau_range, [alpha], data_size=1000, to_print=False)\n",
    "    y_pred = model.predict(X_cur)\n",
    "    alpha_scores.append(mean_absolute_error(y_pred, y_cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(1)**0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_scores[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_scores[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Alpha train uniform distribution\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.plot(alpha_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
